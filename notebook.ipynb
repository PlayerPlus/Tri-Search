{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8047fee8",
   "metadata": {},
   "source": [
    "@Franz Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef770",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120057ae",
   "metadata": {},
   "source": [
    "# Search Algortihms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac9531b",
   "metadata": {},
   "source": [
    "Search is an integral part of AI. It helps in problem solving across a wide variety of domains where a solution isn’t immediately clear. Everyone is familiar with the Breadth First Search algortihm and likely with A\\* and Djikstra's, however their implementation is as trivial as one would think. This certainly holds tru for bi-directional and tri-directional search problems. I will implement several graph search algorithms from scratch with the goal of ultimately solving tri-directional search and achieving minimal node exploration count. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338663c0",
   "metadata": {},
   "source": [
    "# The Search Graph \n",
    "\n",
    "As inspiration from Peter Norvigs famous textbook, Artificial Intelligence, I will implement my search algorithms to calculate a route between two points in Romania while seeking to minimize time and space cost. \n",
    "\n",
    "Additionally, since the Romania graph is relatively small, I will be utilizing the Atlanta graph for additional testing. However, it is too big to display within a Python window like Romania. As a result, when you run the bidirectional tests in **_search_atlanta_tests.py_**, it generates a JSON file in the GeoJSON format. To see the graph, you can use [this](http://geojson.io/) site.\n",
    "\n",
    "If you want to see how **_visualize_graph.py_** is used, take a look at the test functions like `test_bi_ucs_atlanta_custom` in **_search_atlanta_tests.py_**\n",
    "\n",
    "![romania.png](romania/romania.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a47653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import os\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b98941",
   "metadata": {},
   "source": [
    "### 1 - Priority Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73874d42",
   "metadata": {},
   "source": [
    "In all searches that involve calculating path cost or heuristic (e.g. uniform-cost), we have to order our search frontier. It turns out the way that we do this can impact our overall search runtime. To show this, I will implement a priority queue which will help in understanding its performance benefits. For large graphs, sorting all input to a priority queue is impractical. As such, the data structure I implement will have an **amortized O(1) insertion and O(lg n) removal time**. For the purposes of this project, I treat **smaller values as values with higher priority**. For example a value of 1 has a higher priority than a value of 2.\n",
    "\n",
    "\n",
    "#### Mathematical Overview:\n",
    "\n",
    "A priority queue, denoted as \\(Q\\), operates by inserting nodes \\(n\\) with an associated priority. The operation can be defined as:\n",
    "\n",
    "$$Q.insert(n, priority)$$\n",
    "\n",
    "In the context of search algorithms, the priority typically depends on the cost \\(g(n)\\) or the evaluation function \\(f(n) = g(n) + h(n)\\), where \\(h(n)\\) is the heuristic.\n",
    "\n",
    "#### Implementation Details:\n",
    "\n",
    "The priority queue was implemented using a binary heap to efficiently support the operations required for the search algorithms, particularly the extract-min operation, which is critical for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a80f8",
   "metadata": {},
   "source": [
    "**Properties**\n",
    "1. Amortized O(1) insertion and O(log n) removal. \n",
    "2. Preserve FIFO. It is possible for the priority queue to receive two elements with the same priority. In the event that that occurs, the element that joined the priority queue first should be returned first.\n",
    "3. Generalize. The nodes provided to the priority queue will be Python tuples in the form of `(priority, payload)`. We assume that the datatype for `priority` is a standard Python datatype (i.e. `int`, `float`, `str`, etc.). The `payload` can be of any datatype (standard or custom).\n",
    "4. It is possible for duplicate nodes to enter the queue. (i.e. identical priority, identical payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53c42571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue(object):\n",
    "    \"\"\"\n",
    "    A queue structure where each element is served in order of priority.\n",
    "\n",
    "    Elements in the queue are popped based on the priority with higher priority\n",
    "    elements being served before lower priority elements.  If two elements have\n",
    "    the same priority, they will be served in the order they were added to the\n",
    "    queue.\n",
    "\n",
    "    Traditionally priority queues are implemented with heaps, but there are any\n",
    "    number of implementation options.\n",
    "\n",
    "    (Hint: take a look at the module heapq)\n",
    "\n",
    "    Attributes:\n",
    "        queue (list): Nodes added to the priority queue.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a new Priority Queue.\"\"\"\n",
    "\n",
    "        self.queue = []\n",
    "        self.counter = 0\n",
    "\n",
    "    def pop(self):\n",
    "       \n",
    "        \"\"\"\n",
    "        Pop the top priority node from the queue.\n",
    "\n",
    "        Returns:\n",
    "        The node with the highest priority.\n",
    "        \"\"\"\n",
    "        if self.size() == 0: #Check for empty\n",
    "            raise IndexError(\"There are no items in the queue.\")\n",
    "        \n",
    "        elif self.size() == 1: #I hardcoded this base case to simplify the implementation\n",
    "            return_node = self.queue[0]\n",
    "            self.queue.pop(0)\n",
    "        \n",
    "        else: \n",
    "            return_node = self.queue[0]\n",
    "            self.queue[0], heapify_index = self.queue[-1], 0 #Swap last and first item and then heapify it downwards\n",
    "            self.queue.pop(-1) #Delete/Pop the last item \n",
    "        \n",
    "            index_left_child = heapify_index * 2 + 1 #Set up child indixes for heapified node\n",
    "            index_right_child = heapify_index * 2 + 2\n",
    "        \n",
    "            #While left or right children exist to potentially swap\n",
    "            while index_left_child < self.size() or index_right_child < self.size(): \n",
    "                smallest = heapify_index\n",
    "\n",
    "                #If left child exists and < than heapified node or if == same and counter is smaller, set smallest to left child\n",
    "                if index_left_child < self.size() and ((self.queue[index_left_child][0] < self.queue[smallest][0]) \n",
    "                                                       or ((self.queue[index_left_child][0] == self.queue[smallest][0]) \n",
    "                                                           and (self.queue[index_left_child][1] < self.queue[smallest][1]))):\n",
    "                    smallest = index_left_child\n",
    "                #Same for the right\n",
    "                if index_right_child < self.size() and ((self.queue[index_right_child][0] < self.queue[smallest][0]) \n",
    "                                                       or ((self.queue[index_right_child][0] == self.queue[smallest][0]) \n",
    "                                                           and (self.queue[index_right_child][1] < self.queue[smallest][1]))):\n",
    "                    smallest = index_right_child\n",
    "\n",
    "                if smallest == heapify_index: #Break if heapified node \n",
    "                    break\n",
    "\n",
    "                # Swap with the smallest child\n",
    "                self.queue[heapify_index], self.queue[smallest] = self.queue[smallest], self.queue[heapify_index]\n",
    "                heapify_index = smallest\n",
    "\n",
    "                index_left_child = heapify_index * 2 + 1\n",
    "                index_right_child = heapify_index * 2 + 2\n",
    "\n",
    "        return (return_node[0], return_node[2])\n",
    "        \n",
    "    def update(self, node, updated_priority):\n",
    "        \"\"\"\n",
    "        Updates priority value of queue for A* and UCS to a smaller value if found in A*\n",
    "        Loops through and updates. \n",
    "        \"\"\"\n",
    "        loop = True\n",
    "        \n",
    "        for i in range(len(self.queue)):\n",
    "            \n",
    "            if (self.queue[i][2] == node) and (loop == True):\n",
    "                #current = node\n",
    "                self.queue[i][0] = updated_priority\n",
    "                \n",
    "                if i != 0:\n",
    "                    current_index = i\n",
    "                    parent_index = int((current_index - 1) // 2)\n",
    "                \n",
    "                    #Heapfiy up\n",
    "                    while (((self.queue[current_index][0] < \n",
    "                           self.queue[parent_index][0]) or (self.queue[current_index][0] == \n",
    "                           self.queue[parent_index][0] and self.queue[current_index][1] < \n",
    "                           self.queue[parent_index][1])) and (current_index != 0)):\n",
    "                    \n",
    "                        temp = self.queue[current_index]\n",
    "                        self.queue[current_index] = self.queue[parent_index]\n",
    "                        self.queue[parent_index] = temp\n",
    "                           \n",
    "                        #update current and parent index\n",
    "                        current_index = parent_index\n",
    "                        if current_index != 0:\n",
    "                           parent_index = int((parent_index - 1) // 2)\n",
    "                           \n",
    "                    loop = False\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Queue iterator.\"\"\"\n",
    "\n",
    "        return iter(sorted(self.queue))\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Priority Queue to string.\"\"\"\n",
    "\n",
    "        return 'PQ:%s' % self.queue\n",
    "\n",
    "    def append(self, node):\n",
    "        \"\"\"\n",
    "        Append a node to the queue.\n",
    "\n",
    "        Args:\n",
    "            node: Comparable Object to be added to the priority queue.\n",
    "        \n",
    "        I am building a min-heap as implementation. I conserve the min-heap property by heapifying every new node \n",
    "        as long as it's smaller than it's parent.\n",
    "        \"\"\"\n",
    "        #Restructure the tuple into a list to keep track of insertion order\n",
    "        node_list = []\n",
    "        node_list.append(node[0])\n",
    "        node_list.append(self.counter)\n",
    "        node_list.append(node[1])\n",
    "        self.counter = self.counter + 1\n",
    "        \n",
    "        if self.size() == 0:\n",
    "            self.queue.append(node_list)\n",
    "        else: \n",
    "            self.queue.append(node_list)\n",
    "            new_node_index = self.size() - 1\n",
    "            parent_index = int((new_node_index - 1) // 2)\n",
    "            \n",
    "            while((parent_index >= 0 and (node_list[0] < self.queue[parent_index][0])) \n",
    "                  or (node_list[0] == self.queue[parent_index][0] \n",
    "                      and node_list[1] < self.queue[parent_index][1])): #Heapify, while parent is bigger than inserted node, swap them\n",
    "                \n",
    "                temp_parent_node = self.queue[parent_index]\n",
    "                self.queue[parent_index] = node_list\n",
    "                self.queue[new_node_index] = temp_parent_node\n",
    "                new_node_index = parent_index\n",
    "                parent_index = int((parent_index -1) // 2) #Will reach -1 if new node has lowest priority, adding and conditional\n",
    "            \n",
    "        return \"Append Successful\"\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        \"\"\"\n",
    "        Containment Check operator for 'in'\n",
    "\n",
    "        Args:\n",
    "            key: The key to check for in the queue.\n",
    "\n",
    "        Returns:\n",
    "            True if key is found in queue, False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        return key in [n[-1] for n in self.queue]\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Compare this Priority Queue with another Priority Queue.\n",
    "\n",
    "        Args:\n",
    "            other (PriorityQueue): Priority Queue to compare against.\n",
    "\n",
    "        Returns:\n",
    "            True if the two priority queues are equivalent.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.queue == other.queue\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"\n",
    "        Get the current size of the queue.\n",
    "\n",
    "        Returns:\n",
    "            Integer of number of items in queue.\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.queue)\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Reset queue to empty (no nodes).\"\"\"\n",
    "\n",
    "        self.queue = []\n",
    "\n",
    "    def top(self):\n",
    "        \"\"\"\n",
    "        Get the top item in the queue.\n",
    "\n",
    "        Returns:\n",
    "            The first item stored in the queue.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.queue[0]\n",
    "    \n",
    "    def get_nodes(self):\n",
    "        nodes = []\n",
    "        for i in range(len(self.queue)):\n",
    "            nodes.append(self.queue[i][2])\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f27b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_append_and_pop\"!\n",
      "UnitTest passed successfully for \"test_fifo_property\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestPriorityQueue\n",
    "\n",
    "TestPriorityQueue(\"test_append_and_pop\").test_append_and_pop(PriorityQueue)\n",
    "TestPriorityQueue(\"test_fifo_property\").test_fifo_property(PriorityQueue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2f352",
   "metadata": {},
   "source": [
    "### 2 - Breadth First Search (BFS)\n",
    "\n",
    "Breadth-First Search is a straightforward algorithm perfect for exploring nodes level by level in an unweighted graph or tree.\n",
    "\n",
    "#### Mathematical Overview:\n",
    "\n",
    "BFS treats all edge costs as equal, typically considering them to be 1. The nodes are expanded in order of their depth:\n",
    "\n",
    "$$f(n) = g(n)$$\n",
    "\n",
    "where \\(g(n)\\) is the depth of node \\(n\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9975558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadth_first_search(graph, start, goal):\n",
    "    \"\"\"\n",
    "    Implement breadth-first-search.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "\n",
    "    if start == goal: return []\n",
    "    \n",
    "    bfs_queue = [start]\n",
    "    visited = set()\n",
    "    parent_dir = {start: None}\n",
    "    path = []\n",
    "    #cost = 0\n",
    "    \n",
    "    while len(bfs_queue) > 0:\n",
    "        current = bfs_queue.pop(0)\n",
    "\n",
    "        if current == goal:\n",
    "            #path = []\n",
    "            while current is not None:\n",
    "                path.insert(0, current)\n",
    "                current = parent_dir[current]\n",
    "            return path\n",
    "        \n",
    "        temp_list = []\n",
    "        \n",
    "        for neighbor in graph.neighbors(current):\n",
    "            if neighbor not in visited and neighbor not in parent_dir:\n",
    "                \n",
    "                if neighbor == goal:\n",
    "                    parent_dir[neighbor] = current\n",
    "                    current = neighbor\n",
    "                    while current is not None:\n",
    "                        path.insert(0, current)\n",
    "                        current = parent_dir[current]\n",
    "                    return path\n",
    "                    \n",
    "                parent_dir[neighbor] = current\n",
    "                temp_list.append(neighbor)\n",
    "        \n",
    "        temp_list = sorted(temp_list)\n",
    "        #print(temp_list)\n",
    "        for node in temp_list:\n",
    "            bfs_queue.append(node)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c18435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestBFS\n",
    "\n",
    "TestBFS(\"test_valid_paths\").test_valid_paths(breadth_first_search)\n",
    "TestBFS(\"test_optimal_paths\").test_optimal_paths(breadth_first_search)\n",
    "TestBFS(\"test_explored_counts\").test_explored_counts(breadth_first_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4449f",
   "metadata": {},
   "source": [
    "### 3 - Uniform-cost search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef72bfd",
   "metadata": {},
   "source": [
    "Implement uniform-cost search, using PriorityQueue as your frontier. From now on, PriorityQueue should be your default frontier.\n",
    "\n",
    "`uniform_cost_search()` returns a path from the start to the goal node as a list of nodes.\n",
    "\n",
    "Uniform Cost Search generalizes BFS to handle varied costs and is particularly useful where paths have different weights.\n",
    "\n",
    "#### Mathematical Overview:\n",
    "\n",
    "Here, the priority of a node \\(n\\) is directly based on the cumulative cost to reach \\(n\\):\n",
    "\n",
    "$$f(n) = g(n)$$\n",
    "\n",
    "ensuring that the least costly paths are explored first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_cost_search(graph, start, goal):\n",
    "    \"\"\"\n",
    "    Uniform_cost_search.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    #Check if start == goal, and if return []\n",
    "    if start == goal:\n",
    "        return []\n",
    "    \n",
    "    #Assign priority queue and add start as first element (root) with priority of 0\n",
    "    priority_q = PriorityQueue()\n",
    "    start_tuple = (0, start)\n",
    "    priority_q.append(start_tuple)\n",
    "    visited = set()\n",
    "    parent_dir = {start: [\"stop\", 0]}\n",
    "    path = []\n",
    "    \n",
    "    #While top in our priority queue is not equal to the goal node\n",
    "    while (priority_q.top()[2] != goal):\n",
    "        \n",
    "        #Assign current node that is being explored, pop it off the priority queue\n",
    "        #Initialize temporary list = []\n",
    "        current = priority_q.pop()\n",
    "        temp_list = []\n",
    "        \n",
    "        #Loop through neighbors of current that are not in visited\n",
    "        for neighbor in graph.neighbors(current[1]):\n",
    "            \n",
    "            #Save them to a temporary list of tuples with \n",
    "            #edge cost from current to neighbor + total edge cost to current\n",
    "            \n",
    "            if neighbor not in visited:\n",
    "                \n",
    "                total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parent_dir[current[1]][1]\n",
    "                #Make current the parent of neighbor if not in parent_dir or smaller than existing entry\n",
    "                if neighbor not in parent_dir:\n",
    "                    \n",
    "                    #Make current the parent of neighbor\n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    temp_cost = total_edge_cost\n",
    "                    temp_list.append((temp_cost, neighbor))\n",
    "                    \n",
    "                elif total_edge_cost < parent_dir[neighbor][1]:\n",
    "                    \n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    #edge_diff = parent_dir[neighbor][1] - total_edge_cost\n",
    "                    priority_q.update(neighbor, total_edge_cost)\n",
    "        \n",
    "        #Mark current as visited \n",
    "        visited.add(current[1])\n",
    "        \n",
    "        sort_and_append(priority_q, temp_list)\n",
    "        #Sort the list alphabetically based on their tuple[1] value which will be a single character type string\n",
    "        #sorted_tuples = sorted(temp_list, key=lambda x: x[1])\n",
    "        \n",
    "        #Append the list values to the priority queue, which will handle the prioritization\n",
    "        #for element in sorted_tuples:\n",
    "            #priority_q.append(element)\n",
    "            \n",
    "        #If top of priority queue == goal\n",
    "        #backtrack from goal node to start using parent_directory and build path, return path\n",
    "        if priority_q.top()[2] == goal:\n",
    "            back_track = goal\n",
    "            \n",
    "            while back_track != \"stop\":\n",
    "                path.insert(0, back_track)\n",
    "                back_track = parent_dir[back_track][0]\n",
    "                \n",
    "            return path\n",
    "    \n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae71e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_ucs_romania\", uniform_cost_search)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_ucs_romania\", uniform_cost_search)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_ucs_romania\", uniform_cost_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757397f0",
   "metadata": {},
   "source": [
    "### 4 - A* search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96268402",
   "metadata": {},
   "source": [
    "Implement A* search using Euclidean distance as your heuristic. You'll need to implement `euclidean_dist_heuristic()` then pass that function to `a_star()` as the heuristic parameter. We provide `null_heuristic()` as a baseline heuristic to test against when calling a_star tests.\n",
    "\n",
    "A* Search combines the actual cost to reach a node and a heuristic estimate of the cost to reach the goal, providing an efficient pathfinding capability.\n",
    "\n",
    "#### Mathematical Overview:\n",
    "\n",
    "The A* selection function is:\n",
    "\n",
    "$$f(n) = g(n) + h(n)$$\n",
    "\n",
    "optimizing both cost and heuristic assessments to find the most efficient route."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329ff68",
   "metadata": {},
   "source": [
    "#### The Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b9331c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_heuristic(graph, v, goal):\n",
    "    \"\"\"\n",
    "    Null heuristic used as a base line.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        v (str): Key for the node to calculate from.\n",
    "        goal (str): Key for the end node to calculate to.\n",
    "\n",
    "    Returns:\n",
    "        0\n",
    "    \"\"\"\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def euclidean_dist_heuristic(graph, u, v):\n",
    "    \"\"\"\n",
    "    Warm-up exercise: Implement the euclidean distance heuristic.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        u (str): Key for the first node to calculate from.\n",
    "        v (str): Key for the second node to calculate to.\n",
    "\n",
    "    Returns:\n",
    "        Euclidean distance between the `u` node and the `v` node\n",
    "        Round the result to 3 decimal places (if applicable)\n",
    "    \"\"\"\n",
    "\n",
    "   # print(graph.nodes[u]['pos'])\n",
    "    x_diff = graph.nodes[u]['pos'][0] - graph.nodes[v]['pos'][0]\n",
    "    y_diff = graph.nodes[u]['pos'][1] - graph.nodes[v]['pos'][1]\n",
    "    \n",
    "    return round(math.sqrt(x_diff**2 + y_diff**2), 3)\n",
    "    # TODO: finish this function!͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e462bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_euclidean_distance\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestEuclideanHeuristic\n",
    "\n",
    "TestEuclideanHeuristic(\"test_euclidean_distance\").test_euclidean_distance(euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edd7eb",
   "metadata": {},
   "source": [
    "#### The A* Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1427267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star(graph, start, goal, heuristic=euclidean_dist_heuristic):\n",
    "    \"\"\"\n",
    "    Warm-up exercise: Implement A* algorithm.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "        heuristic: Function to determine distance heuristic.\n",
    "            Default: euclidean_dist_heuristic.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    \n",
    "    #Check if start == goal, and if return []\n",
    "    if start == goal:\n",
    "        return []\n",
    "    \n",
    "    #Assign priority queue and add start as first element (root) with priority of 0 + euclidean distance to goal (heuristic)\n",
    "    priority_q = PriorityQueue()\n",
    "    start_tuple = (heuristic(graph, start, goal), start)\n",
    "    priority_q.append(start_tuple)\n",
    "    visited = set()\n",
    "    parent_dir = {start: [\"stop\", 0]}\n",
    "    path = []\n",
    "    \n",
    "    #While top in our priority queue is not equal to the goal node\n",
    "    while (priority_q.top()[2] != goal):\n",
    "        \n",
    "        #Assign current node that is being explored, pop it off the priority queue\n",
    "        #Initialize temporary list = []\n",
    "        current = priority_q.pop()\n",
    "        temp_list = []\n",
    "        \n",
    "        #Loop through neighbors of current that are not in visited\n",
    "        for neighbor in graph.neighbors(current[1]):\n",
    "            \n",
    "            #Save them to a temporary list of tuples with \n",
    "            #(edge cost from current to neighbor + euclidean distance from neighbor to goal (heuristic), node)\n",
    "            \n",
    "            if neighbor not in visited:\n",
    "                \n",
    "                total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parent_dir[current[1]][1]\n",
    "                #Make current the parent of neighbor if not in parent_dir or smaller than existing entry\n",
    "                if neighbor not in parent_dir:\n",
    "                    \n",
    "                    #Make current the parent of neighbor\n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    temp_cost = total_edge_cost + heuristic(graph, neighbor, goal)\n",
    "                    temp_list.append((temp_cost, neighbor))\n",
    "                    \n",
    "                elif total_edge_cost < parent_dir[neighbor][1]:\n",
    "                    \n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    #edge_diff = parent_dir[neighbor][1] - total_edge_cost\n",
    "                    priority_q.update(neighbor, total_edge_cost + heuristic(graph, neighbor, goal))\n",
    "        \n",
    "        #Mark current as visited \n",
    "        visited.add(current[1])\n",
    "        \n",
    "        #Sort the list alphabetically based on their tuple[1] value which will be a single character type string\n",
    "        sorted_tuples = sorted(temp_list, key=lambda x: x[1])\n",
    "        \n",
    "        #Append the list values to the priority queue, which will handle the prioritization\n",
    "        for element in sorted_tuples:\n",
    "            priority_q.append(element)\n",
    "            \n",
    "        #If top of priority queue == goal\n",
    "        #backtrack from goal node to start using parent_directory and build path, return path\n",
    "        if priority_q.top()[2] == goal:\n",
    "            back_track = goal\n",
    "            \n",
    "            while back_track != \"stop\":\n",
    "                path.insert(0, back_track)\n",
    "                back_track = parent_dir[back_track][0]\n",
    "                \n",
    "            return path\n",
    "        \n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afeab513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_a_star_null_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_null_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_null_romania.test_explored_counts\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_explored_counts\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f2837",
   "metadata": {},
   "source": [
    "### Bidirectional A* search \n",
    "\n",
    "Bi-directional A* conducts two synchronized A* searches, one from the start and another from the goal, which can significantly reduce the search space under certain conditions.\n",
    "\n",
    "### Mathematical Overview and Stopping Condition:\n",
    "\n",
    "This method uses two heuristics, \\(h_1(n)\\) for the start-to-node heuristic and \\(h_2(n)\\) for the goal-to-node heuristic. The searches meet effectively when:\n",
    "\n",
    "$$g_1(n) + g_2(n) \\geq f_{\\text{min}}$$\n",
    "\n",
    "where \\(g_1\\) and \\(g_2\\) are the costs from the start and goal to the node \\(n\\) respectively, and \\(f_{\\text{min}}\\) is the smallest path cost found.\n",
    "\n",
    "### Ira Pohl's Contribution:\n",
    "\n",
    "Pohl introduced a refined stopping condition for bidirectional search, focusing on ensuring that the combined paths' cost from start and goal to a meeting point \\(n\\) does not exceed the best known path cost. This is mathematically captured as:\n",
    "\n",
    "$$C(x) + C(y) - h(x, y) \\leq C(p)$$\n",
    "\n",
    "where \\(x\\) and \\(y\\) are nodes from the opposite ends of the search and \\(p\\) is their meeting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "eaf8118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_a_star(graph, start, goal,\n",
    "                         heuristic=euclidean_dist_heuristic):\n",
    "    \"\"\"\n",
    "    Bidirectional A*.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "        heuristic: Function to determine distance heuristic.\n",
    "        Default: euclidean_dist_heuristic.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    #Start condition and initializations\n",
    "    if start == goal: return []\n",
    "\n",
    "    q_forward, q_backward = PriorityQueue(), PriorityQueue()\n",
    "    visited_f, visited_b = set(), set()\n",
    "    forward = True\n",
    "    q_forward.append((0, start))\n",
    "    q_backward.append((0, goal))\n",
    "    parents_f = {start: [\"stop\", 0]}\n",
    "    parents_b = {goal: [\"stop\", 0]}\n",
    "    \n",
    "    while (not visited_f.intersection(visited_b)): #while explored sets from forward and backward don't intersect\n",
    "        \n",
    "        if forward:   \n",
    "            current = q_forward.pop()\n",
    "            temp_list = []      \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in visited_f:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_f[current[1]][1]\n",
    "                    if neighbor not in parents_f: #If neighbor has no parent yet\n",
    "                        parents_f[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_cost = total_edge_cost + heuristic(graph, neighbor, goal)\n",
    "                        temp_list.append((temp_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_f[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_f[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q_forward.update(neighbor, temp_cost) #Update queue\n",
    "            \n",
    "            visited_f.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q_forward, temp_list) #Sort list alphabetically and append to forward queue\n",
    "            \n",
    "            forward = False\n",
    "        \n",
    "        #Backward \n",
    "        else: \n",
    "            current = q_backward.pop()\n",
    "            temp_list = []      \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in visited_b:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_b[current[1]][1]\n",
    "                    if neighbor not in parents_b: #If neighbor has no parent yet\n",
    "                        parents_b[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_cost = total_edge_cost + heuristic(graph, neighbor, start)\n",
    "                        temp_list.append((temp_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_b[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_b[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q_backward.update(neighbor, temp_cost) #Update queue\n",
    "            \n",
    "            visited_b.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q_backward, temp_list) #Sort list alphabetically and append to forward queue\n",
    "        \n",
    "            forward = True\n",
    "        \n",
    "    #As while loop stopped, explored sets intersect on one element\n",
    "    intersection_node = next(iter(visited_f.intersection(visited_b))) #Find intersection node\n",
    "    \n",
    "    crossover_points = list(visited_f.intersection(set((q_backward.get_nodes() + list(visited_b)))))\n",
    "\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, parents_b[point][1] + parents_f[point][1]])\n",
    "        \n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    path_costs = [sublist for sublist in path_costs if intersection_node != sublist[0]]\n",
    "    intersection_cost = parents_b[intersection_node][1] + parents_f[intersection_node][1]\n",
    "    \n",
    "    if intersection_cost > path_costs[0][1]:\n",
    "        \n",
    "        forward_path = backtrack_and_append(path_costs[0][0], parents_f)\n",
    "        backward_path = backtrack_and_append(path_costs[0][0], parents_b)\n",
    "    \n",
    "        backward_path = backward_path[:-1] #Remove last element\n",
    "        backward_path.reverse()\n",
    "    \n",
    "        path = forward_path + backward_path\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    \n",
    "    forward_path = backtrack_and_append(intersection_node, parents_f)\n",
    "    backward_path = backtrack_and_append(intersection_node, parents_b)\n",
    "    \n",
    "    backward_path = backward_path[:-1] #Remove last element\n",
    "    backward_path.reverse()\n",
    "    \n",
    "    path = forward_path + backward_path\n",
    "\n",
    "    return path\n",
    "   \n",
    "    \n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)\n",
    "\n",
    "def backtrack_and_append(intersection_node, parent_directory):\n",
    "    path = []\n",
    "    back_track = intersection_node\n",
    "    while back_track != \"stop\":\n",
    "        path.insert(0, back_track)\n",
    "        back_track = parent_directory[back_track][0]\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "db86f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_explored_counts\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_explored_counts\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f7888f",
   "metadata": {},
   "source": [
    "### Tridirectional UCS search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac6e89",
   "metadata": {},
   "source": [
    "The Tri-Directional Search algorithm is an enhanced variant of pathfinding algorithms, designed to optimize node exploration by simultaneously initiating searches from three strategically chosen nodes—commonly the start, goal, and an intermediary node which acts as an additional source or target. This approach is predicated on minimizing the explored search space more efficiently than bi-directional search, potentially halving the exploration overhead under optimal conditions.\n",
    "\n",
    "#### Mathematical Foundation\n",
    "\n",
    "Tri-directional search leverages the theoretical framework of graph traversal to expedite convergence towards a solution by initiating multiple frontiers of exploration. Here, the graph is defined as G = (V, E) with V representing vertices and E representing edges. Each edge e connecting vertices u and v can optionally carry a weight w(u, v), which influences pathfinding in weighted scenarios.\n",
    "\n",
    "#### Optimization Objective:\n",
    "\n",
    "The core objective in the tri-directional approach is to minimize the total number of explored nodes, denoted as |N|, where N ⊆ V. This is achieved by optimizing the selection of the intermediary node and dynamically balancing the frontier expansion across the three nodes based on real-time heuristic evaluations.\n",
    "\n",
    "#### Search Dynamics:\n",
    "\n",
    "The search progresses through simultaneous expansion from three nodes using either BFS or DFS, potentially enhanced with heuristic functions akin to A*. For heuristic-driven searches, each node n in the frontier employs a cost function f(n) = g(n) + h(n), where:\n",
    "\n",
    "- g(n) is the exact cost path from the start to n,\n",
    "- h(n) is a heuristic estimate of the cost from n to the goal.\n",
    "\n",
    "In the tri-directional setup, this formulation is adapted for three interacting frontiers, necessitating a triplet of heuristic functions each tailored for path estimation from their respective origins to their destinations.\n",
    "\n",
    "#### Stopping Conditions\n",
    "\n",
    "The algorithm's termination is predicated on the convergence of the search frontiers, which can be theoretically articulated through the lens of optimal stopping conditions.\n",
    "\n",
    "##### Intersection-Based Stopping:\n",
    "\n",
    "The primary stopping criterion is the detection of an intersection among the sets of nodes explored by each frontier, denoted as S1, S2, and S3. Mathematically, the search can cease when:\n",
    "\n",
    "    S1 ∩ S2 ≠ ∅, or S1 ∩ S3 ≠ ∅, or S2 ∩ S3 ≠ ∅\n",
    "\n",
    "This condition ensures that a connecting path exists, albeit not necessarily the shortest.\n",
    "\n",
    "##### Cost-Based Stopping:\n",
    "\n",
    "Extending on Ira Pohl’s insights from bidirectional search, the optimal path guarantee can be framed as follows: if P is a path connecting the start to the goal, then the search can terminate when the summed minimal heuristic evaluations of any two fronts, plus the interconnecting path cost, exceed the best-known path cost:\n",
    "\n",
    "    min{f(x) | x ∈ Si} + min{f(y) | y ∈ Sj} + d(x, y) > C(P)\n",
    "\n",
    "where i, j ∈ {1, 2, 3}, i ≠ j, and d(x, y) represents the direct path cost between nodes x and y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "2910cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tridirectional_search(graph, goals):\n",
    "    \n",
    "    ### SET UP \n",
    "    if goals[0] == goals[1] == goals[2]: return [] \n",
    "    #test = False\n",
    "    #if goals == ['b', 'm', 'o']:\n",
    "        #test = True\n",
    "    q1, q2, q3 = PriorityQueue(), PriorityQueue(), PriorityQueue()\n",
    "    v1, v2, v3 = set(), set(), set()\n",
    "    one, two, no_need_to_compare = True, True, False\n",
    "    \n",
    "    q1.append((0, goals[0]))\n",
    "    q2.append((0, goals[1]))\n",
    "    q3.append((0, goals[2]))\n",
    "\n",
    "    parents_1 = {goals[0]: [\"stop\", 0]}\n",
    "    parents_2 = {goals[1]: [\"stop\", 0]}\n",
    "    parents_3 = {goals[2]: [\"stop\", 0]}\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    ### INITIAL LOOP TO FIND FIRST INTERSECTION\n",
    "    \n",
    "    while ((q1.top()[2] not in v1.union(v2, v3)) and (q2.top()[2] not in v1.union(v2, v3)) and \n",
    "           (q3.top()[2] not in v1.union(v2, v3))):\n",
    "        \n",
    "        if one: #Search 1\n",
    "            current = q1.pop()\n",
    "            temp_list = []   \n",
    "            \n",
    "            \n",
    "            if q1.size() != 0:\n",
    "                if q1.top()[2] in v1.union(v2, v3):\n",
    "                    v1.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "            \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v1:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_1[current[1]][1]\n",
    "                    if neighbor not in parents_1: #If neighbor has no parent yet\n",
    "                        parents_1[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_1[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_1[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q1.update(neighbor, total_edge_cost) #Update queue \n",
    "            v1.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q1, temp_list) #Sort list alphabetically and append to queue\n",
    "            one = False\n",
    "        elif two: #Search 2 \n",
    "            current = q2.pop()\n",
    "            temp_list = []   \n",
    "            \n",
    "            if q2.size() != 0:\n",
    "                if q2.top()[2] in v1.union(v2, v3):\n",
    "                    v2.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "                    \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v2:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_2[current[1]][1]\n",
    "                    if neighbor not in parents_2: #If neighbor has no parent yet\n",
    "                        parents_2[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_2[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_2[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q2.update(neighbor, total_edge_cost) #Update queue\n",
    "            v2.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q2, temp_list) #Sort list alphabetically and append to queue\n",
    "            two = False\n",
    "        else: #Search 3 \n",
    "            current = q3.pop()\n",
    "            temp_list = []    \n",
    "            \n",
    "            if q3.size() != 0:\n",
    "                if q3.top()[2] in v1.union(v2, v3):\n",
    "                    v3.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "                    \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v3:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_3[current[1]][1]\n",
    "                    if neighbor not in parents_3: #If neighbor has no parent yet\n",
    "                        parents_3[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_3[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_3[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q3.update(neighbor, total_edge_cost) #Update queue\n",
    "            v3.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q3, temp_list) #Sort list alphabetically and append to queue\n",
    "            one = True \n",
    "            two = True     \n",
    "            \n",
    "    ####################################\n",
    "        \n",
    "    ### OPTIMIZE FIRST PATH AB\n",
    "    met = who_met_3(q1, q2, q3, v1, v2, v3, parents_1, parents_2, parents_3)\n",
    "    eval('v' + str(met[1])).add(met[0])\n",
    "    eval('v' + str(met[2])).add(met[0])\n",
    "    ab_intersect = met[0]\n",
    "    crossover_points = list(eval('v' + str(met[1])).intersection(set((eval('q' + str(met[2])).get_nodes() + \n",
    "                                                                             list(eval('v' + str(met[2])))))))\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, eval('parents_' + str(met[2]))[point][1] + \n",
    "                           eval('parents_' + str(met[1]))[point][1]])\n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    path_costs = [sublist for sublist in path_costs if ab_intersect != sublist[0]]\n",
    "    intersection_cost = eval('parents_' + str(met[2]))[met[0]][1] + eval('parents_' + str(met[1]))[met[0]][1]\n",
    "    if len(path_costs) != 0:\n",
    "        if intersection_cost > path_costs[0][1]:\n",
    "            ab_intersect = path_costs[0][0]\n",
    "            eval('v' + str(met[1])).add(ab_intersect)\n",
    "            eval('v' + str(met[2])).add(ab_intersect)\n",
    "    ab_path_cost = eval('parents_' + str(met[2]))[ab_intersect][1] + eval('parents_' + str(met[1]))[ab_intersect][1]\n",
    "    #####################################\n",
    "    \n",
    "    ### Continue Search with 3rd Search I\n",
    "    temp1, temp2 = [met[1], met[2]], ['1', '2','3']\n",
    "    result = [item for item in temp2 if item not in temp1] #result contains leftover search number\n",
    "    q_continue = eval('q' + str(result[0]))\n",
    "    parents_continue = eval('parents_' + str(result[0]))\n",
    "\n",
    "    while (q_continue.top()[2] not in eval('v' + str(met[1])).union(eval('v' + str(met[2])))):\n",
    "        current = q_continue.pop()\n",
    "        temp_list = [] \n",
    "        \"\"\"\n",
    "        if q_continue.size() != 0:\n",
    "            if q_continue.top()[2] in eval('v' + str(met[1])).union(eval('v' + str(met[2]))):\n",
    "                sort_and_append(q_continue, temp_list)\n",
    "                break\n",
    "         \"\"\"\n",
    "        for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "            total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_continue[current[1]][1]\n",
    "            if neighbor not in parents_continue: #If neighbor has no parent yet\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "            elif total_edge_cost < parents_continue[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                q_continue.update(neighbor, total_edge_cost) #Update queue               \n",
    "        sort_and_append(q_continue, temp_list) #Sort list alphabetically and append to queue\n",
    "        \n",
    "    #####################################\n",
    "    \n",
    "    ### OPTIMIZE SECOND PATH C - \n",
    "    c_search_x_initial = who_met_2(q_continue.top()[2], eval('v' + str(met[1])), met[1], eval('v' + str(met[2])), met[2])  \n",
    "    crossover_points = list(eval('v' + str(c_search_x_initial)).intersection(set((q_continue.get_nodes()))))\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, parents_continue[point][1] + eval('parents_' + str(c_search_x_initial))[point][1]])    \n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    path_costs = [sublist for sublist in path_costs if q_continue.top()[2] != sublist[0]]\n",
    "    intersection_cost = parents_continue[q_continue.top()[2]][1] + eval('parents_' + str(c_search_x_initial))[q_continue.top()[2]][1]\n",
    "    intersect_node_c_x_initial = q_continue.top()[2]\n",
    "    if len(path_costs) != 0:\n",
    "        if intersection_cost > path_costs[0][1]:\n",
    "            intersect_node_c_x_initial = path_costs[0][0] #Update intersect node \n",
    "    c_x_path_cost_1 = parents_continue[intersect_node_c_x_initial][1] + eval('parents_' + str(c_search_x_initial))[intersect_node_c_x_initial][1]\n",
    "    \n",
    "    ######################################\n",
    "\n",
    "    ### Continue Search with 3rd Search II\n",
    "    options = [met[1], met[2]]\n",
    "    c_search_x_second = [item for item in options if item != c_search_x_initial][0]\n",
    "    \n",
    "    if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "        no_need_to_compare = True\n",
    "        \n",
    "    while (q_continue.top()[2] not in eval('v' + str(c_search_x_second))) and not no_need_to_compare:\n",
    "        if q_continue.size() == 1:\n",
    "            if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "                break\n",
    "                \n",
    "        current = q_continue.pop()\n",
    "        temp_list = []      \n",
    "        \n",
    "        if q_continue.size() != 0:\n",
    "            if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "                break\n",
    "                \n",
    "        for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "            total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_continue[current[1]][1]\n",
    "            if neighbor not in parents_continue: #If neighbor has no parent yet\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "            elif total_edge_cost < parents_continue[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                q_continue.update(neighbor, total_edge_cost) #Update queue                 \n",
    "        sort_and_append(q_continue, temp_list) #Sort list alphabetically and append to queue    \n",
    "        \n",
    "    if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "        no_need_to_compare = True\n",
    "    \n",
    "    #######################################\n",
    "    \n",
    "    ### OPTIMIZE THIRD PATH C - (if applicable)\n",
    "    if not no_need_to_compare:\n",
    "        crossover_points = list(eval('v' + str(c_search_x_second)).intersection(set((q_continue.get_nodes()))))\n",
    "        path_costs = []\n",
    "        intersect_node_c_x_second = q_continue.top()[2]\n",
    "        for point in crossover_points:\n",
    "            path_costs.append([point, parents_continue[point][1] + eval('parents_' + str(c_search_x_second))[point][1]])    \n",
    "        path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "        path_costs = [sublist for sublist in path_costs if intersect_node_c_x_second != sublist[0]]\n",
    "        if not no_need_to_compare:\n",
    "            intersection_cost = parents_continue[intersect_node_c_x_second][1] + eval('parents_' + str(c_search_x_second))[intersect_node_c_x_second][1]\n",
    "            if len(path_costs) != 0:\n",
    "                if intersection_cost > path_costs[0][1]:\n",
    "                    intersect_node_c_x_second = path_costs[0][0] #Update intersect node \n",
    "            c_x_path_cost_2 = parents_continue[intersect_node_c_x_second][1] + eval('parents_' + str(c_search_x_second))[intersect_node_c_x_second][1]\n",
    "    \n",
    "    ######################################\n",
    "    \n",
    "    ### Build Path\n",
    "    #Case 1: CB was determined to be longer than max of (AB, AC) and therefore never searched for\n",
    "    if no_need_to_compare:\n",
    "        c_path = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp_path = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp_path.reverse()\n",
    "        c_path = c_path + temp_path\n",
    "        if c_search_x_initial == met[1]:\n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        else: \n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "            \n",
    "        full_path = c_path + ab_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "    \n",
    "    #Case 2: CB was found. If CA <= CB\n",
    "    if c_x_path_cost_1 <= c_x_path_cost_2:\n",
    "        c_path = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp_path = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp_path.reverse()\n",
    "        c_path_1 = c_path + temp_path\n",
    "        if (c_x_path_cost_2 < ab_path_cost) and (c_x_path_cost_1 != c_x_path_cost_2):\n",
    "            temp1 = backtrack_and_append(intersect_node_c_x_second, eval('parents_' + str(c_search_x_second)))\n",
    "            temp2 = backtrack_and_append(intersect_node_c_x_second, parents_continue)\n",
    "            temp2.reverse()\n",
    "            c_path_2 = temp1 + temp2\n",
    "            full_path = c_path_2 + c_path_1\n",
    "            result_path = filter_nodes(full_path)\n",
    "            return result_path\n",
    "        else:\n",
    "            if c_search_x_initial == met[1]:\n",
    "                ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "                b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "                b_path.reverse()\n",
    "                ab_path = ab_path + b_path\n",
    "            else: \n",
    "                ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "                b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "                b_path.reverse()\n",
    "                ab_path = ab_path + b_path\n",
    "            full_path = c_path_1 + ab_path\n",
    "            result_path = filter_nodes(full_path)\n",
    "            return result_path\n",
    "    \n",
    "    #Case 3: CB was found. If CA > CB\n",
    "    c_path = backtrack_and_append(intersect_node_c_x_second, parents_continue)\n",
    "    temp_path = backtrack_and_append(intersect_node_c_x_second, eval('parents_' + str(c_search_x_second)))\n",
    "    temp_path.reverse()\n",
    "    c_path = c_path + temp_path\n",
    "    if (c_x_path_cost_1 < ab_path_cost) and (c_x_path_cost_1 != c_x_path_cost_2):\n",
    "        temp1 = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp2 = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp2.reverse()\n",
    "        c_path_2 = temp1 + temp2\n",
    "        full_path = c_path_2 + c_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "    else:\n",
    "        if c_search_x_second == met[1]:\n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        else: \n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        \n",
    "        full_path = c_path + ab_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "        \n",
    "##########################################  \n",
    "##########################################  \n",
    "##########################################  \n",
    "\n",
    "def filter_nodes(full_path):\n",
    "    result = []\n",
    "    for i in range(len(full_path) - 1):\n",
    "        if full_path[i] != full_path[i + 1]:\n",
    "            result.append(full_path[i])\n",
    "    result.append(full_path[-1])\n",
    "    return result\n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)\n",
    "\n",
    "def backtrack_and_append(intersection_node, parent_directory):\n",
    "    path, counter = [], 0\n",
    "    back_track = intersection_node\n",
    "    while back_track != \"stop\":\n",
    "        path.insert(0, back_track)\n",
    "        back_track = parent_directory[back_track][0]\n",
    "    return path\n",
    "    \n",
    "def who_met_2(q1, v2,num2, v3,num3):\n",
    "    if q1 in v2:\n",
    "        return str(num2)\n",
    "    elif q1 in v3:\n",
    "        return str(num3)\n",
    "    return None\n",
    "\n",
    "def who_met_3(q1, q2, q3, v1, v2, v3, p1, p2, p3):\n",
    "    intersections = []\n",
    "    if q1.top()[2] in v2:\n",
    "        intersections.append((q1.top()[2], '1', '2', p1[q1.top()[2]][1] + p2[q1.top()[2]][1]))\n",
    "    if q1.top()[2] in v3:\n",
    "        intersections.append((q1.top()[2], '1', '3', p1[q1.top()[2]][1] + p3[q1.top()[2]][1]))\n",
    "    if q2.top()[2] in v1:\n",
    "        intersections.append((q2.top()[2], '2', '1', p2[q2.top()[2]][1] + p1[q2.top()[2]][1]))\n",
    "    if q2.top()[2] in v3:\n",
    "        intersections.append((q2.top()[2], '2', '3', p2[q2.top()[2]][1] + p3[q2.top()[2]][1]))\n",
    "    if q3.top()[2] in v1:\n",
    "        intersections.append((q3.top()[2], '3', '1', p3[q3.top()[2]][1] + p1[q3.top()[2]][1]))\n",
    "    if q3.top()[2] in v2:\n",
    "        intersections.append((q3.top()[2], '3', '2', p3[q3.top()[2]][1] + p2[q3.top()[2]][1]))\n",
    "    if intersections:\n",
    "        return min(intersections, key=lambda x: x[3])\n",
    "    else:\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
