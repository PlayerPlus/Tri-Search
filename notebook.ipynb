{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8047fee8",
   "metadata": {},
   "source": [
    "### If you are reading this notebook on the GitHub, please go to [README](./README.md) and follow installation instructions to set everything up locally, it's an interactive notebook and you need a local setup to execute the cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef770",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120057ae",
   "metadata": {},
   "source": [
    "# CS 6601: Artificial Intelligence - Assignment 1 - Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac9531b",
   "metadata": {},
   "source": [
    "Search is an integral part of AI. It helps in problem solving across a wide variety of domains where a solution isn’t immediately clear.  You will implement several graph search algorithms with the goal of solving bi-directional and tri-directional search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9cd1bd",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "0. [About the Assignment](#about-the-assignment)\n",
    "1. [Submission Instructions](#submission-instructions)\n",
    "2. [Important Files](#important-files)\n",
    "3. [Grading](#grading)\n",
    "4. [Frequently Asked Questions](#faq)\n",
    "5. [Resources](#resources)\n",
    "6. [Coding Time!](#coding-time)\n",
    "7. [Race!](#race)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338663c0",
   "metadata": {},
   "source": [
    "# About the Assignment <a name=\"about-the-assignment\"></a>\n",
    "\n",
    "Your task is to implement several search algorithms that will calculate a route between two points in Romania while seeking to minimize time and space cost. We will be using an undirected network representing a map of Romania (and an optional Atlanta graph used for the Race!).\n",
    "\n",
    "![romania.png](romania/romania.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93381d4f",
   "metadata": {},
   "source": [
    "# Submission Instructions <a name=\"submission-instructions\"></a>\n",
    "\n",
    "The grade you receive for the assignment will be determined as follows:\n",
    "\n",
    "| Section | Points    | Condition |\n",
    "| ------- | --------- | --------- |\n",
    "| [Name](#name) | 1 point | Return your name. |\n",
    "| [Warmup 1](#priority-queue) | 5 points | Implement a Priority Queue from scratch or by modifying Python's `heapq` library. |\n",
    "| [Warmup 2](#bfs) | 5 points | Implement Breadth First Search (BFS). |\n",
    "| [Warmup 3](#ucs) | 10 points | Implement Uniform Cost Search (UCS). |\n",
    "| [Warmup 4](#astar) | 10 points | Implement A* Search. |\n",
    "| [Exercise 1](#bi-ucs) | 20 points | Implement Bidirectional UCS Search. |\n",
    "| [Exercise 2](#bi-astar) | 29 points | Implement Bidirectional A* Search. |\n",
    "| [Exercise 3](#tri-ucs) | 12 points | Implement Tridirectional UCS Search. |\n",
    "| [Exercise 4](#tri-upgraded) | 8 points | Implement Upgraded Tridirectional Search. |\n",
    "| [Race!](#race) | 5 points (Extra Credit) | Implement your best search algorithm for a competition. |\n",
    "\n",
    "All code you will edit is in the `notebook.ipynb` file. In order to obtain your submission file for Gradescope, **save your notebook, then uncomment and run the code cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "e772e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Policy:\n",
      "    \n",
      "      \"I have read the late policy for CS3600/6601.\"\n",
      "    \n",
      "Please type 'yes' to agree and continue>yes\n",
      "\n",
      "\n",
      "Honor Pledge:\n",
      "    \n",
      "      \"I have read the Collaboration and Academic Honesty policy for CS3600/6601.\n",
      "      I certify that I have or will use outside references only in accordance with\n",
      "      this policy, that I have or will cite any such references via code comments,\n",
      "      and that I have not or will not copy any portion of my submission from another\n",
      "      past or current student.\"\n",
      "\n",
      "    \n",
      "Please type 'yes' to agree and continue>yes\n",
      "\n",
      "\n",
      "Converted notebook.ipynb to submission/submission.py\n"
     ]
    }
   ],
   "source": [
    "%run helpers/notebook2script submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ab021",
   "metadata": {},
   "source": [
    "The above code cell will generate a `submission/submission.py` file. Do **NOT** modify this file, directly submit it to Gradescope for grading. You are allowed **two submissions every thirty minutes**. In your Gradescope submission history, you can mark a certain submission as 'Active'. Gradescope automatically marks your most recent submission as the one for grading, so make sure you activate your best submission for grading at the end. The autograder is set to timeout in **10 minutes**, so if your submissions runs for longer than 10 minutes it will be terminated and not graded. Note that in some cases, this will fail to occur due to infinite loops or memory overflow, in which case you will have crased the autograder and should reach on Edstem to see if the teaching staff can manually terminate the autograder for you.\n",
    "\n",
    "**Do NOT erase the `#export` at the top of any cells as it is used by `notebook2script.py` to extract cells for submission.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbfa309",
   "metadata": {},
   "source": [
    "# Important Files <a name=\"important-files\"></a>\n",
    "\n",
    "While you'll only have to edit `notebook.ipynb` and submit the exported `submission.py`, there are a number of other notable files:\n",
    "\n",
    "1. `notebook.ipynb`: Where you'll implement the required methods for your search algorithms.\n",
    "2. `search_basic_tests.py`: Sample basic tests, visualizes the Romania graph.\n",
    "3. `search_submission_tests_grid.py`: Visualizes the search as a grid.\n",
    "4. `search_romania_tests.py`: More comprehensive tests on the Romania graph than `search_basic_tests`.\n",
    "5. `search_atlanta_tests.py`: Tests for the Atlanta graph.\n",
    "6. `search_case_visualizer.py`: For visualizing specific failed cases of interest on the Romania graph.\n",
    "\n",
    "Feel free to play around with provided tests above and to write your own for more comprehensive testing. See the README file for details on how to run them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4638978",
   "metadata": {},
   "source": [
    "#### Visualizing the Atlanta graph:\n",
    "\n",
    "The Atlanta graph is used in the extra credit part of this assignment. However, it is too big to display within a Python window like Romania. As a result, when you run the bidirectional tests in **_search_atlanta_tests.py_**, it generates a JSON file in the GeoJSON format. To see the graph, you can upload it to a private GitHub Gist or use [this](http://geojson.io/) site.\n",
    "\n",
    "If you want to see how **_visualize_graph.py_** is used, take a look at the test functions like `test_bi_ucs_atlanta_custom` in **_search_atlanta_tests.py_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a42c20",
   "metadata": {},
   "source": [
    "# Grading <a name=\"grading\"></a>\n",
    "\n",
    "Points for each section are awarded based on finding the most optimal path (for that search algorithm) and then evaluating the number of nodes explored. To track the number of times a node is explored during the search, the `ExplorableGraph` wrapper is used on the networkx Graph class. Every time you process a node, by calling `graph.neighbors(node)`, the count for that node increases by one. You will need to use one of these methods to add a node's neighbors to the search queue, just be careful not to call it unnecessarily throughout your code. We have created the `graph.get_edge_weight(u, v)` method to be used to access edge weights between two nodes, `u` and `v`. All other normal `networkx` Graph operations can be performed. Exercise specific details can be found in the exercise descriptions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579e29",
   "metadata": {},
   "source": [
    "# Frequently Asked Questions <a name=\"faq\"></a>\n",
    "\n",
    "> **General**\n",
    "> 1. Do **NOT** create a copy of the graph structure for any of the algorithms or computations. We refer to this as \"caching neighbors\" and it is illegal.\n",
    "> 2. A walkthrough video will be released with the assignment release on Edstem. It is highly recommended that you watch the video for guidance on how to get started on the project as well as tips for individual exercises.\n",
    "> 3. This is a difficult assignment! Get started early, use office hours, and don't give up!\n",
    "\n",
    "> **Error Messages (Gradescope and Local)**\n",
    "> 1. **NoneType object is not subscriptable** - This usually occurs when you return a path that is not completely connected (a pair of successive nodes in your path are not connected) or if your path returned is empty when it is not supposed to be empty.\n",
    "> 2. **Path does not go from start to goal or is invalid** - (Gradescope) The path returned by your algorithm does not have the start and end goals at their respective positions; does not have the correct start and end goals; is not the shortest path to the goal; or is not a complete/connected path.\n",
    "> 3. **Path is longer than optimal path** - (Gradescope) Your path cost is greater than the expected optimal path cost/benchmark.\n",
    "> 4. **Nodes explored should be from a valid frontier and should be kept to a minimum** - (Gradescope) Your algorithm is exploring more nodes than necessary or is exploring nodes that should not be explored in that particular test. This is independent of whether or not your path is correct.\n",
    "> 5. **On average for the failed test case(s), excluding cases where path is longer than optimal: \n",
    "number of nodes explored more than the benchmark = xyz** - (Gradescope) The average number of nodes explored in excess by your algorithm (includes only cases where path was optimal)\n",
    "> 6. **Path cost is incorrect** - (Gradescope) The cost of your path is incorrect.\n",
    "> 7. **List index was out of range** - (Gradescope) This is likely due to the fact that your code may not be generalized properly. While we provide the Romania map for local testing, the map on Gradescope is not identical and node labels may not be one character strings. (i.e. multicharacter strings, integers, floats, etc.) Make sure your code is generalized!\n",
    "\n",
    "> **Grading**\n",
    "> 1. **The grade you see in Gradecope is the grade that you will get, unless an OSI violation is detected**. In the event that an OSI violation is detected, you will be notified at some point after the assignment closure for administrative steps. So please, check with teaching staff before you do anything that might result in an OSI violation.\n",
    "> 2. **Are in-person and OMSCS folk graded together?** No. They are two separate sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa8512",
   "metadata": {},
   "source": [
    "# Resources <a name=\"resources\"></a>\n",
    "\n",
    "General resources:\n",
    "* Canvas Course Videos: Search Module\n",
    "* [R&N slides on Uninformed Search](https://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/chapter03-clean.pdf)\n",
    "* [Informed Search](https://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/chapter04a.pdf)\n",
    "* [Comparing BFS and DFS](https://cs.stanford.edu/people/abisee/tutorial/bfsdfs.html)\n",
    "* [A* Search](https://cs.stanford.edu/people/abisee/tutorial/astar.html)\n",
    "\n",
    "Advanced resources:\n",
    "* [A Star meets Graph Theory](https://github.gatech.edu/omscs6601/assignment_1/raw/master/resources/A%20Star%20meets%20Graph%20Theory.pdf)\n",
    "* [Bi Directional A Star - Slides](https://github.gatech.edu/omscs6601/assignment_1/raw/master/resources/Bi%20Directional%20A%20Star%20-%20Slides.pdf)\n",
    "* [Bi Directional A Star with Additive Approx Bounds](https://github.gatech.edu/omscs6601/assignment_1/raw/master/resources/Bi%20Directional%20A%20Star%20with%20Additive%20Approx%20Bounds.pdf)\n",
    "* [Bi Directional A Star](https://github.gatech.edu/omscs6601/assignment_1/raw/master/resources/Bi%20Directional%20A%20Star.pdf)\n",
    "* [Search Algorithms Slide Deck](https://github.gatech.edu/omscs6601/assignment_1/raw/master/resources/Search%20Algorithms%20Slide%20Deck.pdf)\n",
    "* [Bi Directional Stopping Conditions, Piazza '17](https://docs.google.com/document/d/14Wr2SeRKDXFGdD-qNrBpXjW8INCGIfiAoJ0UkZaLWto/pub)\n",
    "* [Bi Directional Search Visualizations](https://drive.google.com/file/d/1SxhOnAn4uAI17HdTq082PuzQ_jZnp4Nw/view?usp=sharing)\n",
    "* [Piazza: Landmark Example](https://docs.google.com/document/d/1YEptGbSYUtu180MfvmrmA4B6X9ImdI4oOmLaaMRHiCA/pub)\n",
    "\n",
    "Interesting reads - links from Canvas, below the videos:\n",
    "* [Finding Optimal Solutions to Rubik's Cube Using Pattern Databases](https://www.cs.princeton.edu/courses/archive/fall06/cos402/papers/korfrubik.pdf)\n",
    "* [God's Number is 26 in the Quarter-Turn Metric](http://www.cube20.org/qtm/)\n",
    "* [Reach for A∗: An Efficient Point-to-Point Shortest Path Algorithm](http://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/02-search-01-Astart-ALT-Reach.pdf)\n",
    "* [Computing the Shortest Path: A∗ Search Meets Graph Theory](http://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/02-search-Goldberg03tr.pdf)\n",
    "* [Reach-based Routing: A New Approach to Shortest Path Algorithms Optimized for Road Networks](http://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/02-search-Gutman04siam.pdf)\n",
    "\n",
    "\n",
    "**_Please refrain from referring to code/psuedocode from other resources aside from these._**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7900e1",
   "metadata": {},
   "source": [
    "# Coding Time! <a name=\"coding-time\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd21ceb",
   "metadata": {},
   "source": [
    "## Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run helpers/verify_config.py # verify the environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d4d86",
   "metadata": {},
   "source": [
    "## Importing External Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d479b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following two lines make sure anything imported from .py scripts͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁 \n",
    "# is automatically reloaded if edited & saved (e.g. local unit tests or players)͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6719021",
   "metadata": {},
   "source": [
    "**Do NOT modify the cell below! You are only allowed to use the imports in the cell below for this assignment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a47653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import heapq\n",
    "import os\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400e7fd",
   "metadata": {},
   "source": [
    "If you have discussed this assignment at a whiteboard level, got help from Edstem or have used external resources (not provided by the instructors) that you may want to cite, please do so in the cell below as a Python comment! (no need to cite Python or included packages documentation) Make sure that you have checked with the teaching staff whether or not a resources is allowed **BEFORE** you reference that resource!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d1c1a3",
   "metadata": {},
   "source": [
    "<font color='darkred'>\n",
    "* Plagiarism is a **serious offense**. You are responsible for completing your own work. You are not allowed to copy and paste, or paraphrase, or submit materials created or published by others, as if you created the materials. All materials submitted must be your own.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92f156",
   "metadata": {},
   "source": [
    "<font color='darkred'>\n",
    "* All incidents of suspected dishonesty, plagiarism, or violations of the Georgia Tech Honor Code will be subject to the institute’s Academic Integrity procedures. If we observe any (even small) similarities/plagiarisms detected by Gradescope or our TAs, **WE WILL DIRECTLY REPORT ALL CASES TO OSI**, which may, unfortunately, lead to a very harsh outcome. **Consequences can be severe, e.g., academic probation or dismissal, grade penalties, a 0 grade for assignments concerned, and prohibition from withdrawing from the class.**\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd07208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Credits if any͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "# 1)͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁 Warmup 1: I used the idea on how to preserve FIFO from https://docs.python.org/3/library/heapq.html.\n",
    "# 2)͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "# 3)͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6191329",
   "metadata": {},
   "source": [
    "## Your Name (1 Pt) <a name=\"important-files\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a485c721",
   "metadata": {},
   "source": [
    "A simple task to begin the assignment. Return your name from the function aptly called `return_your_name()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def return_your_name() -> str:\n",
    "    \"\"\"Return your first and last name from this function as a string\"\"\"\n",
    "    # TODO: finish this function͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    return \"Franz Adam\"\n",
    "    raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f4722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local test͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "print(return_your_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f874c4d",
   "metadata": {},
   "source": [
    "## Warmups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997c121",
   "metadata": {},
   "source": [
    "We'll start by implementing some simpler optimization and search algorithms before the real exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b98941",
   "metadata": {},
   "source": [
    "### Warmup 1: Priority Queue (5 Pts) <a name=\"priority-queue\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73874d42",
   "metadata": {},
   "source": [
    "In all searches that involve calculating path cost or heuristic (e.g. uniform-cost), we have to order our search frontier. It turns out the way that we do this can impact our overall search runtime.\n",
    "\n",
    "To show this, you'll implement a priority queue which will help you in understanding its performance benefits. For large graphs, sorting all input to a priority queue is impractical. As such, the data structure you implement should have an **amortized O(1) insertion and O(lg n) removal time**. It should do better than the naive implementation in our tests (InsertionSortQueue), which sorts the entire list after every insertion. Note that for this assignment, we treat **smaller values as values with higher priority**. For example a value of 1 has a higher priority than a value of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a80f8",
   "metadata": {},
   "source": [
    "> **Requirements**\n",
    "> 1. Amortized O(1) insertion and O(log n) removal. What common data structure has these characteristics?\n",
    "> 2. Implement the functions `pop` and `append` in the `PriorityQueue` class below at a minimum. You can add extra helper functions with the class if you'd like and you may also implement `remove` if you find that necessary.\n",
    "> 3. Preserve FIFO. It is possible for the priority queue to receive two elements with the same priority. In the event that that occurs, the element that joined the priority queue first should be returned first.\n",
    "> 4. Generalize. The nodes provided to the priority queue will be Python tuples in the form of `(priority, payload)`. You may assume that the datatype for `priority` is a standard Python datatype (i.e. `int`, `float`, `str`, etc.). The `payload` can be of any datatype (standard or custom).\n",
    "> 5. It is possible for duplicate nodes to enter the queue. (i.e. identical priority, identical payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a9de8",
   "metadata": {},
   "source": [
    "> **FAQ**\n",
    "> 1. **What will be input to the Priority Queue?** We feed nodes in the form `(priority, value)` and expect to receive the nodes back in that same form.\n",
    "> 1. **How do I preserve FIFO?** The best hint we can give you is to think about using some sort of a counter to keep track of when each node joined the Priority Queue...\n",
    "> 3. **Can I use Heapq?** Yes. In fact those of you more familiar with Python may find it much easier to just modify `heapq` to satisfy our requirements than to implement a Priority Queue from scratch (as `heapq` does not satisfy the FIFO requirement). However you have to reference `heapq` documentation yourself. The value in this exercise comes from being able to implement a Priority Queue from scratch. (You might see something like this in a coding interview!)\n",
    "> 4. **Are the local tests comprehensive?** No. Passing local tests does not guarantee that you will pass Gradescope. Try thinking about different scenarios and writing your own tests too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53c42571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class PriorityQueue(object):\n",
    "    \"\"\"\n",
    "    A queue structure where each element is served in order of priority.\n",
    "\n",
    "    Elements in the queue are popped based on the priority with higher priority\n",
    "    elements being served before lower priority elements.  If two elements have\n",
    "    the same priority, they will be served in the order they were added to the\n",
    "    queue.\n",
    "\n",
    "    Traditionally priority queues are implemented with heaps, but there are any\n",
    "    number of implementation options.\n",
    "\n",
    "    (Hint: take a look at the module heapq)\n",
    "\n",
    "    Attributes:\n",
    "        queue (list): Nodes added to the priority queue.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a new Priority Queue.\"\"\"\n",
    "\n",
    "        self.queue = []\n",
    "        self.counter = 0\n",
    "\n",
    "    def pop(self):\n",
    "       \n",
    "        \"\"\"\n",
    "        Pop the top priority node from the queue.\n",
    "\n",
    "        Returns:\n",
    "        The node with the highest priority.\n",
    "        \"\"\"\n",
    "        if self.size() == 0: #Check for empty\n",
    "            raise IndexError(\"There are no items in the queue.\")\n",
    "        \n",
    "        elif self.size() == 1: #I hardcoded this base case to simplify the implementation\n",
    "            return_node = self.queue[0]\n",
    "            self.queue.pop(0)\n",
    "        \n",
    "        else: \n",
    "            return_node = self.queue[0]\n",
    "            self.queue[0], heapify_index = self.queue[-1], 0 #Swap last and first item and then heapify it downwards\n",
    "            self.queue.pop(-1) #Delete/Pop the last item \n",
    "        \n",
    "            index_left_child = heapify_index * 2 + 1 #Set up child indixes for heapified node\n",
    "            index_right_child = heapify_index * 2 + 2\n",
    "        \n",
    "            #While left or right children exist to potentially swap\n",
    "            while index_left_child < self.size() or index_right_child < self.size(): \n",
    "                smallest = heapify_index\n",
    "\n",
    "                #If left child exists and < than heapified node or if == same and counter is smaller, set smallest to left child\n",
    "                if index_left_child < self.size() and ((self.queue[index_left_child][0] < self.queue[smallest][0]) \n",
    "                                                       or ((self.queue[index_left_child][0] == self.queue[smallest][0]) \n",
    "                                                           and (self.queue[index_left_child][1] < self.queue[smallest][1]))):\n",
    "                    smallest = index_left_child\n",
    "                #Same for the right\n",
    "                if index_right_child < self.size() and ((self.queue[index_right_child][0] < self.queue[smallest][0]) \n",
    "                                                       or ((self.queue[index_right_child][0] == self.queue[smallest][0]) \n",
    "                                                           and (self.queue[index_right_child][1] < self.queue[smallest][1]))):\n",
    "                    smallest = index_right_child\n",
    "\n",
    "                if smallest == heapify_index: #Break if heapified node \n",
    "                    break\n",
    "\n",
    "                # Swap with the smallest child\n",
    "                self.queue[heapify_index], self.queue[smallest] = self.queue[smallest], self.queue[heapify_index]\n",
    "                heapify_index = smallest\n",
    "\n",
    "                index_left_child = heapify_index * 2 + 1\n",
    "                index_right_child = heapify_index * 2 + 2\n",
    "\n",
    "        return (return_node[0], return_node[2])\n",
    "\n",
    "    def remove(self, node):\n",
    "        \"\"\"\n",
    "        Remove a node from the queue.\n",
    "\n",
    "        Hint: You might require this in ucs. However, you may\n",
    "        choose not to use it or to define your own method.\n",
    "\n",
    "        Args:\n",
    "            node (tuple): The node to remove from the queue.\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def update(self, node, updated_priority):\n",
    "        \"\"\"\n",
    "        Updates priority value of queue for A* and UCS to a smaller value if found in A*\n",
    "        Loops through and updates. \n",
    "        \"\"\"\n",
    "        loop = True\n",
    "        \n",
    "        for i in range(len(self.queue)):\n",
    "            \n",
    "            if (self.queue[i][2] == node) and (loop == True):\n",
    "                #current = node\n",
    "                self.queue[i][0] = updated_priority\n",
    "                \n",
    "                if i != 0:\n",
    "                    current_index = i\n",
    "                    parent_index = int((current_index - 1) // 2)\n",
    "                \n",
    "                    #Heapfiy up\n",
    "                    while (((self.queue[current_index][0] < \n",
    "                           self.queue[parent_index][0]) or (self.queue[current_index][0] == \n",
    "                           self.queue[parent_index][0] and self.queue[current_index][1] < \n",
    "                           self.queue[parent_index][1])) and (current_index != 0)):\n",
    "                    \n",
    "                        temp = self.queue[current_index]\n",
    "                        self.queue[current_index] = self.queue[parent_index]\n",
    "                        self.queue[parent_index] = temp\n",
    "                           \n",
    "                        #update current and parent index\n",
    "                        current_index = parent_index\n",
    "                        if current_index != 0:\n",
    "                           parent_index = int((parent_index - 1) // 2)\n",
    "                           \n",
    "                    loop = False\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Queue iterator.\"\"\"\n",
    "\n",
    "        return iter(sorted(self.queue))\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Priority Queue to string.\"\"\"\n",
    "\n",
    "        return 'PQ:%s' % self.queue\n",
    "\n",
    "    def append(self, node):\n",
    "        \"\"\"\n",
    "        Append a node to the queue.\n",
    "\n",
    "        Args:\n",
    "            node: Comparable Object to be added to the priority queue.\n",
    "        \n",
    "        I am building a min-heap as implementation. I conserve the min-heap property by heapifying every new node \n",
    "        as long as it's smaller than it's parent.\n",
    "        \"\"\"\n",
    "        #Restructure the tuple into a list to keep track of insertion order\n",
    "        node_list = []\n",
    "        node_list.append(node[0])\n",
    "        node_list.append(self.counter)\n",
    "        node_list.append(node[1])\n",
    "        self.counter = self.counter + 1\n",
    "        \n",
    "        if self.size() == 0:\n",
    "            self.queue.append(node_list)\n",
    "        else: \n",
    "            self.queue.append(node_list)\n",
    "            new_node_index = self.size() - 1\n",
    "            parent_index = int((new_node_index - 1) // 2)\n",
    "            \n",
    "            while((parent_index >= 0 and (node_list[0] < self.queue[parent_index][0])) \n",
    "                  or (node_list[0] == self.queue[parent_index][0] \n",
    "                      and node_list[1] < self.queue[parent_index][1])): #Heapify, while parent is bigger than inserted node, swap them\n",
    "                \n",
    "                temp_parent_node = self.queue[parent_index]\n",
    "                self.queue[parent_index] = node_list\n",
    "                self.queue[new_node_index] = temp_parent_node\n",
    "                new_node_index = parent_index\n",
    "                parent_index = int((parent_index -1) // 2) #Will reach -1 if new node has lowest priority, adding and conditional\n",
    "            \n",
    "        return \"Append Successful\"\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        \"\"\"\n",
    "        Containment Check operator for 'in'\n",
    "\n",
    "        Args:\n",
    "            key: The key to check for in the queue.\n",
    "\n",
    "        Returns:\n",
    "            True if key is found in queue, False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        return key in [n[-1] for n in self.queue]\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Compare this Priority Queue with another Priority Queue.\n",
    "\n",
    "        Args:\n",
    "            other (PriorityQueue): Priority Queue to compare against.\n",
    "\n",
    "        Returns:\n",
    "            True if the two priority queues are equivalent.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.queue == other.queue\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"\n",
    "        Get the current size of the queue.\n",
    "\n",
    "        Returns:\n",
    "            Integer of number of items in queue.\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.queue)\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Reset queue to empty (no nodes).\"\"\"\n",
    "\n",
    "        self.queue = []\n",
    "\n",
    "    def top(self):\n",
    "        \"\"\"\n",
    "        Get the top item in the queue.\n",
    "\n",
    "        Returns:\n",
    "            The first item stored in the queue.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.queue[0]\n",
    "    \n",
    "    def get_nodes(self):\n",
    "        nodes = []\n",
    "        for i in range(len(self.queue)):\n",
    "            nodes.append(self.queue[i][2])\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f27b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_append_and_pop\"!\n",
      "UnitTest passed successfully for \"test_fifo_property\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestPriorityQueue\n",
    "\n",
    "TestPriorityQueue(\"test_append_and_pop\").test_append_and_pop(PriorityQueue)\n",
    "TestPriorityQueue(\"test_fifo_property\").test_fifo_property(PriorityQueue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2f352",
   "metadata": {},
   "source": [
    "### Warmup 2: BFS (5 Pts) <a name=\"bfs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaefc497",
   "metadata": {},
   "source": [
    "To get you started with handling graphs, implement and test breadth-first search over the test network.\n",
    "\n",
    "You'll complete this by writing the `breadth_first_search()` method. This returns a path of nodes from a given start node to a given end node, as a list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc13f40",
   "metadata": {},
   "source": [
    "> **Requirements**\n",
    "> 1. Implement the `breadth_first_search()` method below.\n",
    "> 2. If the start and goal are the same, simply return an empty list like `[]`.\n",
    "> 3. Return the best path found via BFS as a Python list from the start node to the goal node (inclusive).\n",
    "> 4. You can obtain a dictionary of the neighbors of a node by calling `graph.neighbors(node)`.\n",
    "> 5. Sort the neighbors of a node alphabetically before adding them to the queue.\n",
    "> 6. Make sure no node is explored more than once.\n",
    "> 7. Implement the optimization trick which reduces the number of explored nodes (required for passing the autograder). You may find it useful to re-watch the Canvas videos for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aee9c5",
   "metadata": {},
   "source": [
    "> **FAQ**\n",
    "> 1. **Are there multiple correct paths possible?** No. If you follow the above instructions, each pair of start and goal nodes will result in a unique solution.\n",
    "> 2. **Do I need Priority Queue for this?** No. BFS does not need to use a priority queue, a simple FIFO queue using a Python `list` should be sufficient. You may use your priority queue implementation if you'd like.\n",
    "> 3. **Why does it say I don't have the right path when my path cost is shorter?** Remember, BFS treats all edges as having a cost of 1, so the true path cost does not come into play!!\n",
    "> 4. **I am having trouble reconstructing my optimal path. What should I do?** You can either try to keep track of where you came from and reconstruct the path by chaining parent information, or you can store entire paths in your frontier so that when you find the goal node you can just return the path found without having to do reconstruction.\n",
    "> 5. **Why does it say my path is invalid?** Did you return the path as a list of nodes including both the start and the goal node? Did you make sure that the path is a valid path and doesn't skip around? (Traverse the graph by hand to make sure it is valid)\n",
    "> 6. **Why does it say I'm exploring too many nodes?** Did you implement the optimization trick mentioned above? If so, are you making sure that you are not exploring any node more than once? You can check the set of nodes you've explored and how many times they've been explored by calling `graph.explored_nodes`. However please make sure that you remove this call from your code (not comment, fully remove) after you are done debugging as it will cause Gradescope to fail. If you wish to call it repeatedly, make sure you call `graph.reset_search()` to reset the explored count.\n",
    "> 7. **I'm consistently exploring one too many nodes!** Perhaps you are exploring the goal node when you don't actually need to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9975558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def breadth_first_search(graph, start, goal):\n",
    "    \"\"\"\n",
    "    Warm-up exercise: Implement breadth-first-search.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "\n",
    "    if start == goal: return []\n",
    "    \n",
    "    bfs_queue = [start]\n",
    "    visited = set()\n",
    "    parent_dir = {start: None}\n",
    "    path = []\n",
    "    #cost = 0\n",
    "    \n",
    "    while len(bfs_queue) > 0:\n",
    "        current = bfs_queue.pop(0)\n",
    "\n",
    "        if current == goal:\n",
    "            #path = []\n",
    "            while current is not None:\n",
    "                path.insert(0, current)\n",
    "                current = parent_dir[current]\n",
    "            return path\n",
    "        \n",
    "        temp_list = []\n",
    "        \n",
    "        for neighbor in graph.neighbors(current):\n",
    "            if neighbor not in visited and neighbor not in parent_dir:\n",
    "                \n",
    "                if neighbor == goal:\n",
    "                    parent_dir[neighbor] = current\n",
    "                    current = neighbor\n",
    "                    while current is not None:\n",
    "                        path.insert(0, current)\n",
    "                        current = parent_dir[current]\n",
    "                    return path\n",
    "                    \n",
    "                parent_dir[neighbor] = current\n",
    "                temp_list.append(neighbor)\n",
    "        \n",
    "        temp_list = sorted(temp_list)\n",
    "        #print(temp_list)\n",
    "        for node in temp_list:\n",
    "            bfs_queue.append(node)\n",
    "\n",
    "    return None\n",
    "        \n",
    "    #print(graph.neighbors(start))\n",
    "    #for key in graph.neighbors(start):\n",
    "      #  print(key)\n",
    "    \n",
    "    #print(\"--------------\", type(key), \"----------\" ,start ,\"--------------\")\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c18435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestBFS\n",
    "\n",
    "TestBFS(\"test_valid_paths\").test_valid_paths(breadth_first_search)\n",
    "TestBFS(\"test_optimal_paths\").test_optimal_paths(breadth_first_search)\n",
    "TestBFS(\"test_explored_counts\").test_explored_counts(breadth_first_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4449f",
   "metadata": {},
   "source": [
    "### Warmup 3: Uniform-cost search (10 Pts) <a name=\"ucs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef72bfd",
   "metadata": {},
   "source": [
    "Implement uniform-cost search, using PriorityQueue as your frontier. From now on, PriorityQueue should be your default frontier.\n",
    "\n",
    "`uniform_cost_search()` should return a path from the start to the goal node as a list of nodes.\n",
    "\n",
    "The astute of you may have noticed that uniform-cost search is a special case of A*, where the heuristic is the null heuristic, UCS is still different from A* (even though the search behavior will be identical). The difference lies in the fact that UCS is an **uninformed search**, relying solely on path costs, unaware of any heuristics or a node's location. That's why you should **NOT** call A* with a null heuristic, you should **NOT** use heuristics in your implementation, and you should **NOT** be attempting to access a node's position anywhere in your UCS implementation. Doing so will give you a \"call(s) to astar detected\" error on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd967d4",
   "metadata": {},
   "source": [
    "> **Requirements**\n",
    "> 1. Implement the `uniform_cost_search()` method below.\n",
    "> 2. If the start and goal are the same, simply return an empty list like `[]`.\n",
    "> 3. Return the best path found as a Python list from the start node to the goal node (inclusive).\n",
    "> 4. You can obtain a dictionary of the neighbors of a node by calling `graph.neighbors(node)`.\n",
    "> 5. Sort the neighbors of a node alphabetically before processing them.\n",
    "> 6. You can access the edge weight between two nodes `u` and `v` by using `graph.get_edge_weight(u, v)`.\n",
    "> 7. Make sure no node is explored more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def uniform_cost_search(graph, start, goal):\n",
    "    \"\"\"\n",
    "    Warm-up exercise: Implement uniform_cost_search.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    #Check if start == goal, and if return []\n",
    "    if start == goal:\n",
    "        return []\n",
    "    \n",
    "    #Assign priority queue and add start as first element (root) with priority of 0\n",
    "    priority_q = PriorityQueue()\n",
    "    start_tuple = (0, start)\n",
    "    priority_q.append(start_tuple)\n",
    "    visited = set()\n",
    "    parent_dir = {start: [\"stop\", 0]}\n",
    "    path = []\n",
    "    \n",
    "    #While top in our priority queue is not equal to the goal node\n",
    "    while (priority_q.top()[2] != goal):\n",
    "        \n",
    "        #Assign current node that is being explored, pop it off the priority queue\n",
    "        #Initialize temporary list = []\n",
    "        current = priority_q.pop()\n",
    "        temp_list = []\n",
    "        \n",
    "        #Loop through neighbors of current that are not in visited\n",
    "        for neighbor in graph.neighbors(current[1]):\n",
    "            \n",
    "            #Save them to a temporary list of tuples with \n",
    "            #edge cost from current to neighbor + total edge cost to current\n",
    "            \n",
    "            if neighbor not in visited:\n",
    "                \n",
    "                total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parent_dir[current[1]][1]\n",
    "                #Make current the parent of neighbor if not in parent_dir or smaller than existing entry\n",
    "                if neighbor not in parent_dir:\n",
    "                    \n",
    "                    #Make current the parent of neighbor\n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    temp_cost = total_edge_cost\n",
    "                    temp_list.append((temp_cost, neighbor))\n",
    "                    \n",
    "                elif total_edge_cost < parent_dir[neighbor][1]:\n",
    "                    \n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    #edge_diff = parent_dir[neighbor][1] - total_edge_cost\n",
    "                    priority_q.update(neighbor, total_edge_cost)\n",
    "        \n",
    "        #TEST SET UP - START\n",
    "        \n",
    "        #print(\"Euclidean distance for p is: \", heuristic(graph, 'p','f'))\n",
    "        #print(\"Euclidean distance for r is: \", heuristic(graph, 'r','f'))\n",
    "        #print(\"Euclidean distance for s is: \", heuristic(graph, 's','f'))\n",
    "        #print(\"Euclidean distance for f is: \", heuristic(graph, 'f','f'))\n",
    "        #print(\"Euclidean distance for b is: \", heuristic(graph, 'b','f'))\n",
    "        #print(\"Euclidean distance for c is: \", heuristic(graph, 'c','f'))\n",
    "        \n",
    "        #TEST SET UP - END\n",
    "                \n",
    "        \n",
    "        #Mark current as visited \n",
    "        visited.add(current[1])\n",
    "        \n",
    "        sort_and_append(priority_q, temp_list)\n",
    "        #Sort the list alphabetically based on their tuple[1] value which will be a single character type string\n",
    "        #sorted_tuples = sorted(temp_list, key=lambda x: x[1])\n",
    "        \n",
    "        #Append the list values to the priority queue, which will handle the prioritization\n",
    "        #for element in sorted_tuples:\n",
    "            #priority_q.append(element)\n",
    "            \n",
    "        #If top of priority queue == goal\n",
    "        #backtrack from goal node to start using parent_directory and build path, return path\n",
    "        if priority_q.top()[2] == goal:\n",
    "            back_track = goal\n",
    "            \n",
    "            while back_track != \"stop\":\n",
    "                path.insert(0, back_track)\n",
    "                back_track = parent_dir[back_track][0]\n",
    "                \n",
    "            return path\n",
    "\n",
    "    # TODO: finish this function!͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    #raise NotImplementedError\n",
    "    \n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae71e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_ucs_romania\", uniform_cost_search)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_ucs_romania\", uniform_cost_search)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_ucs_romania\", uniform_cost_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757397f0",
   "metadata": {},
   "source": [
    "### Warmup 4: A* search (10 Pts) <a name=\"astar\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96268402",
   "metadata": {},
   "source": [
    "Implement A* search using Euclidean distance as your heuristic. You'll need to implement `euclidean_dist_heuristic()` then pass that function to `a_star()` as the heuristic parameter. We provide `null_heuristic()` as a baseline heuristic to test against when calling a_star tests.\n",
    "\n",
    "The astute of you may have noticed that UCS is a special case of A\\*. Perhaps it may save you some time if you implement A* first, then transfer your code over to UCS, and then make the necessary modifications to make the code reflect the UCS requirements..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ab46a",
   "metadata": {},
   "source": [
    "> **Requirements**\n",
    "> 1. Implement the `euclidean_dist_heuristic()` and the `a_star()` method below.\n",
    "> 2. If the start and goal are the same, simply return an empty list like `[]`.\n",
    "> 3. Return the best path found as a Python list from the start node to the goal node (inclusive).\n",
    "> 4. You can obtain a dictionary of the neighbors of a node by calling `graph.neighbors(node)`.\n",
    "> 5. Sort the neighbors of a node alphabetically before processing them.\n",
    "> 6. You can access the edge weight between two nodes `u` and `v` by using `graph.get_edge_weight(u, v)`.\n",
    "> 7. You can access the `(x, y)` position of a node `u` by using `graph.nodes[u]['pos']`. You may find this useful for calculating the Euclidean heuristic.\n",
    "> 8. Make sure no node is explored more than once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329ff68",
   "metadata": {},
   "source": [
    "#### The Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b9331c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def null_heuristic(graph, v, goal):\n",
    "    \"\"\"\n",
    "    Null heuristic used as a base line.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        v (str): Key for the node to calculate from.\n",
    "        goal (str): Key for the end node to calculate to.\n",
    "\n",
    "    Returns:\n",
    "        0\n",
    "    \"\"\"\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def euclidean_dist_heuristic(graph, u, v):\n",
    "    \"\"\"\n",
    "    Warm-up exercise: Implement the euclidean distance heuristic.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        u (str): Key for the first node to calculate from.\n",
    "        v (str): Key for the second node to calculate to.\n",
    "\n",
    "    Returns:\n",
    "        Euclidean distance between the `u` node and the `v` node\n",
    "        Round the result to 3 decimal places (if applicable)\n",
    "    \"\"\"\n",
    "\n",
    "   # print(graph.nodes[u]['pos'])\n",
    "    x_diff = graph.nodes[u]['pos'][0] - graph.nodes[v]['pos'][0]\n",
    "    y_diff = graph.nodes[u]['pos'][1] - graph.nodes[v]['pos'][1]\n",
    "    \n",
    "    return round(math.sqrt(x_diff**2 + y_diff**2), 3)\n",
    "    # TODO: finish this function!͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e462bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_euclidean_distance\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestEuclideanHeuristic\n",
    "\n",
    "TestEuclideanHeuristic(\"test_euclidean_distance\").test_euclidean_distance(euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edd7eb",
   "metadata": {},
   "source": [
    "### The A* Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1427267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def a_star(graph, start, goal, heuristic=euclidean_dist_heuristic):\n",
    "    \"\"\"\n",
    "    Warm-up exercise: Implement A* algorithm.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "        heuristic: Function to determine distance heuristic.\n",
    "            Default: euclidean_dist_heuristic.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    \n",
    "    #Check if start == goal, and if return []\n",
    "    if start == goal:\n",
    "        return []\n",
    "    \n",
    "    #Assign priority queue and add start as first element (root) with priority of 0 + euclidean distance to goal (heuristic)\n",
    "    priority_q = PriorityQueue()\n",
    "    start_tuple = (heuristic(graph, start, goal), start)\n",
    "    priority_q.append(start_tuple)\n",
    "    visited = set()\n",
    "    parent_dir = {start: [\"stop\", 0]}\n",
    "    path = []\n",
    "    \n",
    "    #While top in our priority queue is not equal to the goal node\n",
    "    while (priority_q.top()[2] != goal):\n",
    "        \n",
    "        #Assign current node that is being explored, pop it off the priority queue\n",
    "        #Initialize temporary list = []\n",
    "        current = priority_q.pop()\n",
    "        temp_list = []\n",
    "        \n",
    "        #Loop through neighbors of current that are not in visited\n",
    "        for neighbor in graph.neighbors(current[1]):\n",
    "            \n",
    "            #Save them to a temporary list of tuples with \n",
    "            #(edge cost from current to neighbor + euclidean distance from neighbor to goal (heuristic), node)\n",
    "            \n",
    "            if neighbor not in visited:\n",
    "                \n",
    "                total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parent_dir[current[1]][1]\n",
    "                #Make current the parent of neighbor if not in parent_dir or smaller than existing entry\n",
    "                if neighbor not in parent_dir:\n",
    "                    \n",
    "                    #Make current the parent of neighbor\n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    temp_cost = total_edge_cost + heuristic(graph, neighbor, goal)\n",
    "                    temp_list.append((temp_cost, neighbor))\n",
    "                    \n",
    "                elif total_edge_cost < parent_dir[neighbor][1]:\n",
    "                    \n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    #edge_diff = parent_dir[neighbor][1] - total_edge_cost\n",
    "                    priority_q.update(neighbor, total_edge_cost + heuristic(graph, neighbor, goal))\n",
    "        \n",
    "        #TEST SET UP - START\n",
    "        #print(\"Euclidean distance for p is: \", heuristic(graph, 'p','f'))\n",
    "        #print(\"Euclidean distance for r is: \", heuristic(graph, 'r','f'))\n",
    "        #print(\"Euclidean distance for s is: \", heuristic(graph, 's','f'))\n",
    "        #print(\"Euclidean distance for f is: \", heuristic(graph, 'f','f'))\n",
    "        #print(\"Euclidean distance for b is: \", heuristic(graph, 'b','f'))\n",
    "        #print(\"Euclidean distance for c is: \", heuristic(graph, 'c','f'))\n",
    "        #print(priority_q.get_nodes())\n",
    "        #TEST SET UP - END\n",
    "                \n",
    "        \n",
    "        #Mark current as visited \n",
    "        visited.add(current[1])\n",
    "        \n",
    "        #Sort the list alphabetically based on their tuple[1] value which will be a single character type string\n",
    "        sorted_tuples = sorted(temp_list, key=lambda x: x[1])\n",
    "        \n",
    "        #Append the list values to the priority queue, which will handle the prioritization\n",
    "        for element in sorted_tuples:\n",
    "            priority_q.append(element)\n",
    "            \n",
    "        #If top of priority queue == goal\n",
    "        #backtrack from goal node to start using parent_directory and build path, return path\n",
    "        if priority_q.top()[2] == goal:\n",
    "            back_track = goal\n",
    "            \n",
    "            while back_track != \"stop\":\n",
    "                path.insert(0, back_track)\n",
    "                back_track = parent_dir[back_track][0]\n",
    "                \n",
    "            return path\n",
    "        \n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afeab513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_a_star_null_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_null_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_null_romania.test_explored_counts\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_explored_counts\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01381c2",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2396d",
   "metadata": {},
   "source": [
    "The following exercises will require you to implement several kinds of bidirectional and tridirectional searches. The benefits of these algorithms over uninformed or unidirectional search are more clearly seen on larger graphs.\n",
    "\n",
    "For these exercises, we recommend you take a look at the resources mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a63ed5",
   "metadata": {},
   "source": [
    "### Exercise 1: Bidirectional uniform-cost search (20 Pts) <a name=\"bi-ucs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432f809",
   "metadata": {},
   "source": [
    "Implement bidirectional uniform-cost search. Remember that this requires starting your search at both the start and goal nodes.\n",
    "\n",
    "`bidirectional_ucs()` should return the path from the start node to the goal node (as a list of nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e00f3",
   "metadata": {},
   "source": [
    "> **Requirements**\n",
    "> 1. Implement the `bidirectional_ucs()` method below.\n",
    "> 2. If the start and goal are the same, simply return an empty list like `[]`.\n",
    "> 3. Return the best path found as a Python list from the start node to the goal node (inclusive).\n",
    "> 4. You can obtain a dictionary of the neighbors of a node by calling `graph.neighbors(node)`.\n",
    "> 5. Sort the neighbors of a node alphabetically before processing them.\n",
    "> 6. You can access the edge weight between two nodes `u` and `v` by using `graph.get_edge_weight(u, v)`.\n",
    "> 7. Make sure no node is explored more than once, regardless of which frontier explored it.\n",
    "> 8. We provide a small margin of error for your explored count when grading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d09ae",
   "metadata": {},
   "source": [
    "> **Hints**\n",
    "> 1. Your optimal path should be the same optimal path found via unidirectional UCS and A*.\n",
    "> 2. Which frontier should you pop first (forwards or backwards)? There are two common approaches, consider trying both to see which one performs better.\n",
    "> 3. When should I stop so that I don't explore too many nodes? We love the resource titled: [Bi Directional Stopping Conditions, Piazza '17](https://docs.google.com/document/d/14Wr2SeRKDXFGdD-qNrBpXjW8INCGIfiAoJ0UkZaLWto/pub)\n",
    "> 4. Think about what statement you can make about the relationship between the length of the path to a node you've just popped off the frontier and the length of the paths that are still on the frontier, as you think about your stopping condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7f535315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def bidirectional_ucs(graph, start, goal):\n",
    "    \"\"\"\n",
    "    Exercise 1: Bidirectional Search.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    \n",
    "    #If start == goal, return [], elif start is neighbor of goal, return [start, goal]\n",
    "    if start == goal: return []\n",
    "    \n",
    "    #Initialize 2 priority qs and visited lists, forward and backward\n",
    "    q_forward, q_backward = PriorityQueue(), PriorityQueue()\n",
    "    visited_f, visited_b = set(), set()\n",
    "    forward = True\n",
    "    \n",
    "    q_forward.append((0, start))\n",
    "    q_backward.append((0, goal))\n",
    "    \n",
    "    #Initialize parent directories\n",
    "    parents_f = {start: [\"stop\", 0]}\n",
    "    parents_b = {goal: [\"stop\", 0]}\n",
    "    \n",
    "    # SET UP COMPLETE - NOW TO THE GOOD STUFF\n",
    "    \n",
    "    while (not visited_f.intersection(visited_b)): #while explored sets from forward and backward don't intersect\n",
    "        #Forward\n",
    "        if forward:   \n",
    "            current = q_forward.pop()\n",
    "            temp_list = []      \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in visited_f:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_f[current[1]][1]\n",
    "                    if neighbor not in parents_f: #If neighbor has no parent yet\n",
    "                        parents_f[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_f[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_f[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q_forward.update(neighbor, total_edge_cost) #Update queue\n",
    "            \n",
    "            visited_f.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q_forward, temp_list) #Sort list alphabetically and append to forward queue\n",
    "            \n",
    "            forward = False\n",
    "        \n",
    "        #Backward \n",
    "        else: \n",
    "            current = q_backward.pop()\n",
    "            temp_list = []      \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in visited_b:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_b[current[1]][1]\n",
    "                    if neighbor not in parents_b: #If neighbor has no parent yet\n",
    "                        parents_b[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_b[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_b[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q_backward.update(neighbor, total_edge_cost) #Update queue\n",
    "            \n",
    "            visited_b.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q_backward, temp_list) #Sort list alphabetically and append to forward queue\n",
    "        \n",
    "            forward = True\n",
    "            \n",
    "        #print(visited_b, visited_f)\n",
    "        \n",
    "    #As while loop stopped, explored sets intersect on one element\n",
    "    intersection_node = next(iter(visited_f.intersection(visited_b))) #Find intersection node\n",
    "    \n",
    "    ###\n",
    "    crossover_points = list(visited_f.intersection(set((q_backward.get_nodes() + list(visited_b)))))\n",
    "    #print(\"Intersection node: \", intersection_node)\n",
    "    #print(\"test crossover fct input, should be set\", set((q_backward.get_nodes() + list(visited_b))))\n",
    "    #print(\"see crossover points: \",crossover_points)\n",
    "\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, parents_b[point][1] + parents_f[point][1]])\n",
    "        \n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    #path_costs = [sublist for sublist in path_costs if intersection_node not in sublist[0]]\n",
    "    path_costs = [sublist for sublist in path_costs if intersection_node != sublist[0]]\n",
    "    #print(\"See sorted path costs list: \", path_costs)\n",
    "    \n",
    "    intersection_cost = parents_b[intersection_node][1] + parents_f[intersection_node][1]\n",
    "    #print(\"intersection cost: \", intersection_cost)\n",
    "    #print(\"Path cost: \", path_costs[0][1])\n",
    "    \n",
    "    if intersection_cost > path_costs[0][1]:\n",
    "        #print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "        forward_path = backtrack_and_append(path_costs[0][0], parents_f)\n",
    "        backward_path = backtrack_and_append(path_costs[0][0], parents_b)\n",
    "    \n",
    "        backward_path = backward_path[:-1] #Remove last element\n",
    "        backward_path.reverse()\n",
    "    \n",
    "        path = forward_path + backward_path\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    \n",
    "    forward_path = backtrack_and_append(intersection_node, parents_f)\n",
    "    backward_path = backtrack_and_append(intersection_node, parents_b)\n",
    "    \n",
    "    backward_path = backward_path[:-1] #Remove last element\n",
    "    backward_path.reverse()\n",
    "    \n",
    "    path = forward_path + backward_path\n",
    "    \n",
    "    #Once intersection is found, assign upper bound to find an alternative intersection point to be sum of edge costs\n",
    "    #from the parent of the intersection node for forward and backward seearch to the intersection node\n",
    "    #The lower bound will be not important but the edge cost form parent of intersection to intersection \n",
    "    #for the respective search.\n",
    "    \n",
    "    #Save total path cost to be sum of total edge cost to intersection for both searches\n",
    "    \n",
    "    #Find all potential crossover points to be the intersection of nodes between the set of \n",
    "    #forward explroed (visited_f and) \n",
    "    #the union of backward explored (visited_b) and backsearch frontier (q_backward)\n",
    "    \n",
    "    #Calculate the total path cost for each crossover point = sum(cost to this point from forward and backward)\n",
    "    \n",
    "    #For the lowest cost crossover point, explore it from the backward frontier\n",
    "    \n",
    "    return path\n",
    "    \n",
    "    #raise NotImplementedError\n",
    "    \n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)\n",
    "\n",
    "def backtrack_and_append(intersection_node, parent_directory):\n",
    "    path = []\n",
    "    back_track = intersection_node\n",
    "    while back_track != \"stop\":\n",
    "        path.insert(0, back_track)\n",
    "        back_track = parent_directory[back_track][0]\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be8564df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_bi_ucs_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_ucs_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_ucs_romania.test_explored_counts\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_bi_ucs_romania\", bidirectional_ucs)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_bi_ucs_romania\", bidirectional_ucs)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_bi_ucs_romania\", bidirectional_ucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f2837",
   "metadata": {},
   "source": [
    "### Exercise 2: Bidirectional A* search (29 Pts) <a name=\"bi-astar\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4134d3",
   "metadata": {},
   "source": [
    "Implement bidirectional A* search. Remember that you need to calculate a heuristic for both the start-to-goal search and the goal-to-start search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cddc61c",
   "metadata": {},
   "source": [
    "> **Requirements**\n",
    "> 1. Implement the `bidirectional_a_star()` method below.\n",
    "> 2. If the start and goal are the same, simply return an empty list like `[]`.\n",
    "> 3. Return the best path found as a Python list from the start node to the goal node (inclusive).\n",
    "> 4. You can obtain a dictionary of the neighbors of a node by calling `graph.neighbors(node)`.\n",
    "> 5. Sort the neighbors of a node alphabetically before processing them.\n",
    "> 6. You can access the edge weight between two nodes `u` and `v` by using `graph.get_edge_weight(u, v)`.\n",
    "> 7. Make sure no node is explored more than once, regardless of which frontier explored it.\n",
    "> 8. We provide a small margin of error for your explored count when grading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e05845",
   "metadata": {},
   "source": [
    "> **Hints**\n",
    "> 1. Your optimal path should be the same optimal path found via unidirectional UCS and A*.\n",
    "> 2. Which frontier should you pop first (forwards or backwards)? There are two common approaches, consider trying both to see which one performs better.\n",
    "> 3. When should I stop so that I don't explore too many nodes? We love the resource titled: [Bi Directional Stopping Conditions, Piazza '17](https://docs.google.com/document/d/14Wr2SeRKDXFGdD-qNrBpXjW8INCGIfiAoJ0UkZaLWto/pub)\n",
    "> 4. Think about what statement you can make about the relationship between the length of the path to a node you've just popped off the frontier and the length of the paths that are still on the frontier, as you think about your stopping condition.\n",
    "> 5. How different is the stopping condition from bidirectional UCS? Perhaps there is some accelerated stopping condition that works for both Bi-UCS and Bi-A*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "eaf8118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def bidirectional_a_star(graph, start, goal,\n",
    "                         heuristic=euclidean_dist_heuristic):\n",
    "    \"\"\"\n",
    "    Exercise 2: Bidirectional A*.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "        heuristic: Function to determine distance heuristic.\n",
    "            Default: euclidean_dist_heuristic.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    #Start condition and initializations\n",
    "    if start == goal: return []\n",
    "\n",
    "    q_forward, q_backward = PriorityQueue(), PriorityQueue()\n",
    "    visited_f, visited_b = set(), set()\n",
    "    forward = True\n",
    "    q_forward.append((0, start))\n",
    "    q_backward.append((0, goal))\n",
    "    parents_f = {start: [\"stop\", 0]}\n",
    "    parents_b = {goal: [\"stop\", 0]}\n",
    "    \n",
    "    while (not visited_f.intersection(visited_b)): #while explored sets from forward and backward don't intersect\n",
    "        \n",
    "        if forward:   \n",
    "            current = q_forward.pop()\n",
    "            temp_list = []      \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in visited_f:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_f[current[1]][1]\n",
    "                    if neighbor not in parents_f: #If neighbor has no parent yet\n",
    "                        parents_f[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_cost = total_edge_cost + heuristic(graph, neighbor, goal)\n",
    "                        temp_list.append((temp_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_f[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_f[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q_forward.update(neighbor, temp_cost) #Update queue\n",
    "            \n",
    "            visited_f.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q_forward, temp_list) #Sort list alphabetically and append to forward queue\n",
    "            \n",
    "            forward = False\n",
    "        \n",
    "        #Backward \n",
    "        else: \n",
    "            current = q_backward.pop()\n",
    "            temp_list = []      \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in visited_b:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_b[current[1]][1]\n",
    "                    if neighbor not in parents_b: #If neighbor has no parent yet\n",
    "                        parents_b[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_cost = total_edge_cost + heuristic(graph, neighbor, start)\n",
    "                        temp_list.append((temp_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_b[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_b[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q_backward.update(neighbor, temp_cost) #Update queue\n",
    "            \n",
    "            visited_b.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q_backward, temp_list) #Sort list alphabetically and append to forward queue\n",
    "        \n",
    "            forward = True\n",
    "            \n",
    "        #print(visited_b, visited_f)\n",
    "        \n",
    "    #As while loop stopped, explored sets intersect on one element\n",
    "    intersection_node = next(iter(visited_f.intersection(visited_b))) #Find intersection node\n",
    "    \n",
    "    ###\n",
    "    crossover_points = list(visited_f.intersection(set((q_backward.get_nodes() + list(visited_b)))))\n",
    "    #print(\"Intersection node: \", intersection_node)\n",
    "    #print(\"test crossover fct input, should be set\", set((q_backward.get_nodes() + list(visited_b))))\n",
    "    #print(\"see crossover points: \",crossover_points)\n",
    "\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, parents_b[point][1] + parents_f[point][1]])\n",
    "        \n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    #path_costs = [sublist for sublist in path_costs if intersection_node not in sublist[0]]\n",
    "    path_costs = [sublist for sublist in path_costs if intersection_node != sublist[0]]\n",
    "    #print(\"See sorted path costs list: \", path_costs)\n",
    "    \n",
    "    intersection_cost = parents_b[intersection_node][1] + parents_f[intersection_node][1]\n",
    "    #print(\"intersection cost: \", intersection_cost)\n",
    "    #print(\"Path cost: \", path_costs[0][1])\n",
    "    \n",
    "    if intersection_cost > path_costs[0][1]:\n",
    "        #print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "        forward_path = backtrack_and_append(path_costs[0][0], parents_f)\n",
    "        backward_path = backtrack_and_append(path_costs[0][0], parents_b)\n",
    "    \n",
    "        backward_path = backward_path[:-1] #Remove last element\n",
    "        backward_path.reverse()\n",
    "    \n",
    "        path = forward_path + backward_path\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    \n",
    "    forward_path = backtrack_and_append(intersection_node, parents_f)\n",
    "    backward_path = backtrack_and_append(intersection_node, parents_b)\n",
    "    \n",
    "    backward_path = backward_path[:-1] #Remove last element\n",
    "    backward_path.reverse()\n",
    "    \n",
    "    path = forward_path + backward_path\n",
    "    \n",
    "    #Once intersection is found, assign upper bound to find an alternative intersection point to be sum of edge costs\n",
    "    #from the parent of the intersection node for forward and backward seearch to the intersection node\n",
    "    #The lower bound will be not important but the edge cost form parent of intersection to intersection \n",
    "    #for the respective search.\n",
    "    \n",
    "    #Save total path cost to be sum of total edge cost to intersection for both searches\n",
    "    \n",
    "    #Find all potential crossover points to be the intersection of nodes between the set of \n",
    "    #forward explroed (visited_f and) \n",
    "    #the union of backward explored (visited_b) and backsearch frontier (q_backward)\n",
    "    \n",
    "    #Calculate the total path cost for each crossover point = sum(cost to this point from forward and backward)\n",
    "    \n",
    "    #For the lowest cost crossover point, explore it from the backward frontier\n",
    "    \n",
    "    return path\n",
    "    \n",
    "    #raise NotImplementedError\n",
    "    \n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)\n",
    "\n",
    "def backtrack_and_append(intersection_node, parent_directory):\n",
    "    path = []\n",
    "    back_track = intersection_node\n",
    "    while back_track != \"stop\":\n",
    "        path.insert(0, back_track)\n",
    "        back_track = parent_directory[back_track][0]\n",
    "    return path\n",
    "    # TODO: finish this function!͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "db86f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_explored_counts\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_explored_counts\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f7888f",
   "metadata": {},
   "source": [
    "### Exercise 3: Tridirectional UCS search (12 Pts) <a name=\"tri-ucs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea405c0",
   "metadata": {},
   "source": [
    "Implement tridirectional search using UCS. Starting from each goal node, perform a uniform-cost search and keep expanding until two of the three searches meet. This should create one continuous path that connects all three nodes. You can return the path in any order. Eg. (1->2->3 == 3->2->1). You may also want to look at the Tri-city search challenge question on Canvas.\n",
    "\n",
    "For example, suppose we have goal nodes `[a,b,c]`. Then what we want you to do is to start at node `a` and expand like in a normal search. However, notice that you will be searching for both nodes `b` and `c` during this search and a similar search will also start from nodes `b` and `c`.\n",
    "\n",
    "**This is not the same as 3 bi-directional searches,** as that would result in 6 frontiers!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaba010",
   "metadata": {},
   "source": [
    "> **Requirements**\n",
    "> 1. Implement the `tridirectional_search()` method below.\n",
    "> 2. If all three goals are the same, simply return an empty list like `[]`.\n",
    "> 3. If there are 2 identical goals (i.e. `[a,b,b]`) then return the path `[a...b]` (i.e. just the path from `a` to `b`). Do **NOT** call your bidirectional searches for this, your tridirectional search should naturally handle this scenario.\n",
    "> 4. Return the best path found as a Python list connecting all three goal nodes (inclusive).\n",
    "> 5. You can obtain a dictionary of the neighbors of a node by calling `graph.neighbors(node)`.\n",
    "> 6. Sort the neighbors of a node alphabetically before processing them.\n",
    "> 7. You can access the edge weight between two nodes `u` and `v` by using `graph.get_edge_weight(u, v)`.\n",
    "> 8. Make sure no node is explored more than once, regardless of which frontier explored it.\n",
    "> 9. We provide a small margin of error for your explored count when grading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6594868b",
   "metadata": {},
   "source": [
    "> **Hints**\n",
    "> 1. **Why can't I just run three bidirectional searches?** If you run three bidirectional searches, you aren’t taking advantage of the team knowledge collected by all the searches, and end up exploring multiple nodes, multiple times, blowing up your explored count. This is a team effort, all three goals should be searching for each other together, sharing information as necessary to prevent exploration of any node more than once.\n",
    "> 2. **Why can’t I just take the first two paths I find and call it a day?** Are you sure that’s guaranteed to be the most optimal path and the third path found is guaranteed to be larger than the two paths you’ve found? This could vary based on your implementation.\n",
    "> 3. **Why can’t I just find all three paths and then take the two shortest ones?** Are you sure you HAVE to find all three paths in order to pick the two shortest ones? You might end up exploring too many nodes in some cases…\n",
    "> 4. **Ok if I can’t do either of the above then what can I even do?** Is it really black and white? Is there really no in-between option?\n",
    "> 5. **How is it possible not to explore any node more than once when there are two searches?** The search is a team effort. All teammates are aware of each other’s knowledge so no node should ever have to be explored more than once.\n",
    "> 6. **Why are there no provided resources?** This is a thinking exercise. You are meant to build upon what you have learned so far from the assignment and to think about what a Tridirectional search brings to the table and how you can deal with those new issues and tricks. Homework isn’t about us giving you the algorithm and you just implementing it in code, there’s no value there really, then it just becomes a test of your Python knowledge. The value here comes from your ability to take what you have learned and take it one step further to build something entirely new and advanced. This is where the value of this assignment lies.\n",
    "> 7. Try creating small graph scenarios on paper to see what interesting situations may arise. This will help you as you try to develop your stopping condition(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810c0bf",
   "metadata": {},
   "source": [
    "![romania.png](romania/romania.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b2f43e",
   "metadata": {},
   "source": [
    "Who met:  ('a', '2', '3', 445)  \n",
    "Q Continue before:  PQ:[[198, 8, 'r'], [211, 1, 'f'], [227, 6, 'v'], [239, 7, 'c'], [269, 9, 'e']]  \n",
    "Intersect with 3rd before:  c  \n",
    "Q Contiune after:  PQ:[[239, 7, 'c'], [269, 9, 'e'], [278, 10, 's'], [319, 11, 'i']]  \n",
    "Intersect with 3rd after:  c  \n",
    "Shortest path:  434  \n",
    "Q Continue Top:  c  \n",
    "V2:  {'o', 'a', 's', 'z'}  \n",
    "Cost:  239  \n",
    "Shortest Path:  434  \n",
    "Q Continue Top:  e  \n",
    "V2:  {'o', 'a', 's', 'z'}  \n",
    "Cost:  269  \n",
    "Shortest Path:  434  \n",
    "Q Continue Top:  s  \n",
    "V2:  {'o', 'a', 's', 'z'}  \n",
    "Cost:  278  \n",
    "Shortest Path:  434  \n",
    "Node after update:  s   \n",
    "\n",
    "Actual: ['b', 'p', 'r', 's', 'o', 'z', 'a', 't', 'l', 'm']  \n",
    "Goal nodes ('b', 'm', 'o')   \n",
    "Expected path is ['o', 's', 'r', 'p', 'b', 'p', 'c', 'd', 'm']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f6c622d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "2910cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def tridirectional_search(graph, goals):\n",
    "    \n",
    "    ### SET UP \n",
    "    if goals[0] == goals[1] == goals[2]: return [] \n",
    "    #test = False\n",
    "    #if goals == ['b', 'm', 'o']:\n",
    "        #test = True\n",
    "    q1, q2, q3 = PriorityQueue(), PriorityQueue(), PriorityQueue()\n",
    "    v1, v2, v3 = set(), set(), set()\n",
    "    one, two, no_need_to_compare = True, True, False\n",
    "    \n",
    "    q1.append((0, goals[0]))\n",
    "    q2.append((0, goals[1]))\n",
    "    q3.append((0, goals[2]))\n",
    "\n",
    "    parents_1 = {goals[0]: [\"stop\", 0]}\n",
    "    parents_2 = {goals[1]: [\"stop\", 0]}\n",
    "    parents_3 = {goals[2]: [\"stop\", 0]}\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    ### INITIAL LOOP TO FIND FIRST INTERSECTION\n",
    "    \n",
    "    while ((q1.top()[2] not in v1.union(v2, v3)) and (q2.top()[2] not in v1.union(v2, v3)) and \n",
    "           (q3.top()[2] not in v1.union(v2, v3))):\n",
    "        \n",
    "        if one: #Search 1\n",
    "            current = q1.pop()\n",
    "            temp_list = []   \n",
    "            \n",
    "            \n",
    "            if q1.size() != 0:\n",
    "                if q1.top()[2] in v1.union(v2, v3):\n",
    "                    v1.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "            \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v1:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_1[current[1]][1]\n",
    "                    if neighbor not in parents_1: #If neighbor has no parent yet\n",
    "                        parents_1[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_1[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_1[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q1.update(neighbor, total_edge_cost) #Update queue \n",
    "            v1.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q1, temp_list) #Sort list alphabetically and append to queue\n",
    "            one = False\n",
    "        elif two: #Search 2 \n",
    "            current = q2.pop()\n",
    "            temp_list = []   \n",
    "            \n",
    "            if q2.size() != 0:\n",
    "                if q2.top()[2] in v1.union(v2, v3):\n",
    "                    v2.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "                    \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v2:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_2[current[1]][1]\n",
    "                    if neighbor not in parents_2: #If neighbor has no parent yet\n",
    "                        parents_2[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_2[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_2[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q2.update(neighbor, total_edge_cost) #Update queue\n",
    "            v2.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q2, temp_list) #Sort list alphabetically and append to queue\n",
    "            two = False\n",
    "        else: #Search 3 \n",
    "            current = q3.pop()\n",
    "            temp_list = []    \n",
    "            \n",
    "            if q3.size() != 0:\n",
    "                if q3.top()[2] in v1.union(v2, v3):\n",
    "                    v3.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "                    \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v3:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_3[current[1]][1]\n",
    "                    if neighbor not in parents_3: #If neighbor has no parent yet\n",
    "                        parents_3[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_3[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_3[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q3.update(neighbor, total_edge_cost) #Update queue\n",
    "            v3.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q3, temp_list) #Sort list alphabetically and append to queue\n",
    "            one = True \n",
    "            two = True       \n",
    "    ####################################\n",
    "        \n",
    "    ### OPTIMIZE FIRST PATH AB\n",
    "    met = who_met_3(q1, q2, q3, v1, v2, v3, parents_1, parents_2, parents_3)\n",
    "    eval('v' + str(met[1])).add(met[0])\n",
    "    eval('v' + str(met[2])).add(met[0])\n",
    "    ab_intersect = met[0]\n",
    "    crossover_points = list(eval('v' + str(met[1])).intersection(set((eval('q' + str(met[2])).get_nodes() + \n",
    "                                                                             list(eval('v' + str(met[2])))))))\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, eval('parents_' + str(met[2]))[point][1] + \n",
    "                           eval('parents_' + str(met[1]))[point][1]])\n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    path_costs = [sublist for sublist in path_costs if ab_intersect != sublist[0]]\n",
    "    intersection_cost = eval('parents_' + str(met[2]))[met[0]][1] + eval('parents_' + str(met[1]))[met[0]][1]\n",
    "    if len(path_costs) != 0:\n",
    "        if intersection_cost > path_costs[0][1]:\n",
    "            ab_intersect = path_costs[0][0]\n",
    "            eval('v' + str(met[1])).add(ab_intersect)\n",
    "            eval('v' + str(met[2])).add(ab_intersect)\n",
    "    ab_path_cost = eval('parents_' + str(met[2]))[ab_intersect][1] + eval('parents_' + str(met[1]))[ab_intersect][1]\n",
    "    #####################################\n",
    "    \n",
    "    ### Continue Search with 3rd Search I\n",
    "    temp1, temp2 = [met[1], met[2]], ['1', '2','3']\n",
    "    result = [item for item in temp2 if item not in temp1] #result contains leftover search number\n",
    "    q_continue = eval('q' + str(result[0]))\n",
    "    parents_continue = eval('parents_' + str(result[0]))\n",
    "\n",
    "    while (q_continue.top()[2] not in eval('v' + str(met[1])).union(eval('v' + str(met[2])))):\n",
    "        current = q_continue.pop()\n",
    "        temp_list = [] \n",
    "        \"\"\"\n",
    "        if q_continue.size() != 0:\n",
    "            if q_continue.top()[2] in eval('v' + str(met[1])).union(eval('v' + str(met[2]))):\n",
    "                sort_and_append(q_continue, temp_list)\n",
    "                break\n",
    "         \"\"\"\n",
    "        for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "            total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_continue[current[1]][1]\n",
    "            if neighbor not in parents_continue: #If neighbor has no parent yet\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "            elif total_edge_cost < parents_continue[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                q_continue.update(neighbor, total_edge_cost) #Update queue               \n",
    "        sort_and_append(q_continue, temp_list) #Sort list alphabetically and append to queue\n",
    "    #####################################\n",
    "    \n",
    "    ### OPTIMIZE SECOND PATH C - \n",
    "    c_search_x_initial = who_met_2(q_continue.top()[2], eval('v' + str(met[1])), met[1], eval('v' + str(met[2])), met[2])  \n",
    "    crossover_points = list(eval('v' + str(c_search_x_initial)).intersection(set((q_continue.get_nodes()))))\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, parents_continue[point][1] + eval('parents_' + str(c_search_x_initial))[point][1]])    \n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    path_costs = [sublist for sublist in path_costs if q_continue.top()[2] != sublist[0]]\n",
    "    intersection_cost = parents_continue[q_continue.top()[2]][1] + eval('parents_' + str(c_search_x_initial))[q_continue.top()[2]][1]\n",
    "    intersect_node_c_x_initial = q_continue.top()[2]\n",
    "    if len(path_costs) != 0:\n",
    "        if intersection_cost > path_costs[0][1]:\n",
    "            intersect_node_c_x_initial = path_costs[0][0] #Update intersect node \n",
    "    c_x_path_cost_1 = parents_continue[intersect_node_c_x_initial][1] + eval('parents_' + str(c_search_x_initial))[intersect_node_c_x_initial][1]\n",
    "    ######################################\n",
    "\n",
    "    ### Continue Search with 3rd Search II\n",
    "    options = [met[1], met[2]]\n",
    "    c_search_x_second = [item for item in options if item != c_search_x_initial][0]\n",
    "    \n",
    "    if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "        no_need_to_compare = True\n",
    "        \n",
    "    while (q_continue.top()[2] not in eval('v' + str(c_search_x_second))) and not no_need_to_compare:\n",
    "        if q_continue.size() == 1:\n",
    "            if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "                break\n",
    "                \n",
    "        current = q_continue.pop()\n",
    "        temp_list = []      \n",
    "        \n",
    "        if q_continue.size() != 0:\n",
    "            if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "                break\n",
    "                \n",
    "        for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "            total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_continue[current[1]][1]\n",
    "            if neighbor not in parents_continue: #If neighbor has no parent yet\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "            elif total_edge_cost < parents_continue[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                q_continue.update(neighbor, total_edge_cost) #Update queue                 \n",
    "        sort_and_append(q_continue, temp_list) #Sort list alphabetically and append to queue    \n",
    "        \n",
    "    if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "        no_need_to_compare = True\n",
    "    #######################################\n",
    "    \n",
    "    ### OPTIMIZE THIRD PATH C - (if applicable)\n",
    "    if not no_need_to_compare:\n",
    "        crossover_points = list(eval('v' + str(c_search_x_second)).intersection(set((q_continue.get_nodes()))))\n",
    "        path_costs = []\n",
    "        intersect_node_c_x_second = q_continue.top()[2]\n",
    "        for point in crossover_points:\n",
    "            path_costs.append([point, parents_continue[point][1] + eval('parents_' + str(c_search_x_second))[point][1]])    \n",
    "        path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "        path_costs = [sublist for sublist in path_costs if intersect_node_c_x_second != sublist[0]]\n",
    "        if not no_need_to_compare:\n",
    "            intersection_cost = parents_continue[intersect_node_c_x_second][1] + eval('parents_' + str(c_search_x_second))[intersect_node_c_x_second][1]\n",
    "            if len(path_costs) != 0:\n",
    "                if intersection_cost > path_costs[0][1]:\n",
    "                    intersect_node_c_x_second = path_costs[0][0] #Update intersect node \n",
    "            c_x_path_cost_2 = parents_continue[intersect_node_c_x_second][1] + eval('parents_' + str(c_search_x_second))[intersect_node_c_x_second][1]\n",
    "    ######################################\n",
    "    \n",
    "    ### Build Path\n",
    "    #Case 1: CB was determined to be longer than max of (AB, AC) and therefore never searched for\n",
    "    if no_need_to_compare:\n",
    "        c_path = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp_path = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp_path.reverse()\n",
    "        c_path = c_path + temp_path\n",
    "        if c_search_x_initial == met[1]:\n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        else: \n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "            \n",
    "        full_path = c_path + ab_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "    \n",
    "    #Case 2: CB was found. If CA <= CB\n",
    "    if c_x_path_cost_1 <= c_x_path_cost_2:\n",
    "        c_path = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp_path = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp_path.reverse()\n",
    "        c_path_1 = c_path + temp_path\n",
    "        if (c_x_path_cost_2 < ab_path_cost) and (c_x_path_cost_1 != c_x_path_cost_2):\n",
    "            temp1 = backtrack_and_append(intersect_node_c_x_second, eval('parents_' + str(c_search_x_second)))\n",
    "            temp2 = backtrack_and_append(intersect_node_c_x_second, parents_continue)\n",
    "            temp2.reverse()\n",
    "            c_path_2 = temp1 + temp2\n",
    "            full_path = c_path_2 + c_path_1\n",
    "            result_path = filter_nodes(full_path)\n",
    "            return result_path\n",
    "        else:\n",
    "            if c_search_x_initial == met[1]:\n",
    "                ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "                b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "                b_path.reverse()\n",
    "                ab_path = ab_path + b_path\n",
    "            else: \n",
    "                ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "                b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "                b_path.reverse()\n",
    "                ab_path = ab_path + b_path\n",
    "            full_path = c_path_1 + ab_path\n",
    "            result_path = filter_nodes(full_path)\n",
    "            return result_path\n",
    "    \n",
    "    #Case 3: CB was found. If CA > CB\n",
    "    c_path = backtrack_and_append(intersect_node_c_x_second, parents_continue)\n",
    "    temp_path = backtrack_and_append(intersect_node_c_x_second, eval('parents_' + str(c_search_x_second)))\n",
    "    temp_path.reverse()\n",
    "    c_path = c_path + temp_path\n",
    "    if (c_x_path_cost_1 < ab_path_cost) and (c_x_path_cost_1 != c_x_path_cost_2):\n",
    "        temp1 = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp2 = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp2.reverse()\n",
    "        c_path_2 = temp1 + temp2\n",
    "        full_path = c_path_2 + c_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "    else:\n",
    "        if c_search_x_second == met[1]:\n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        else: \n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        \n",
    "        full_path = c_path + ab_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "        \n",
    "##########################################  \n",
    "##########################################  \n",
    "##########################################  \n",
    "def filter_nodes(full_path):\n",
    "    result = []\n",
    "    for i in range(len(full_path) - 1):\n",
    "        if full_path[i] != full_path[i + 1]:\n",
    "            result.append(full_path[i])\n",
    "    result.append(full_path[-1])\n",
    "    return result\n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)\n",
    "\n",
    "def backtrack_and_append(intersection_node, parent_directory):\n",
    "    path, counter = [], 0\n",
    "    back_track = intersection_node\n",
    "    while back_track != \"stop\":\n",
    "        path.insert(0, back_track)\n",
    "        back_track = parent_directory[back_track][0]\n",
    "    return path\n",
    "    \n",
    "def who_met_2(q1, v2,num2, v3,num3):\n",
    "    if q1 in v2:\n",
    "        return str(num2)\n",
    "    elif q1 in v3:\n",
    "        return str(num3)\n",
    "    return None\n",
    "\n",
    "def who_met_3(q1, q2, q3, v1, v2, v3, p1, p2, p3):\n",
    "    intersections = []\n",
    "    if q1.top()[2] in v2:\n",
    "        intersections.append((q1.top()[2], '1', '2', p1[q1.top()[2]][1] + p2[q1.top()[2]][1]))\n",
    "    if q1.top()[2] in v3:\n",
    "        intersections.append((q1.top()[2], '1', '3', p1[q1.top()[2]][1] + p3[q1.top()[2]][1]))\n",
    "    if q2.top()[2] in v1:\n",
    "        intersections.append((q2.top()[2], '2', '1', p2[q2.top()[2]][1] + p1[q2.top()[2]][1]))\n",
    "    if q2.top()[2] in v3:\n",
    "        intersections.append((q2.top()[2], '2', '3', p2[q2.top()[2]][1] + p3[q2.top()[2]][1]))\n",
    "    if q3.top()[2] in v1:\n",
    "        intersections.append((q3.top()[2], '3', '1', p3[q3.top()[2]][1] + p1[q3.top()[2]][1]))\n",
    "    if q3.top()[2] in v2:\n",
    "        intersections.append((q3.top()[2], '3', '2', p3[q3.top()[2]][1] + p2[q3.top()[2]][1]))\n",
    "    if intersections:\n",
    "        return min(intersections, key=lambda x: x[3])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "c8c3f70a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_tri_ucs_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_tri_ucs_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_tri_ucs_romania.test_explored_counts\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestTriSearchAlgorithms\n",
    "\n",
    "TestTriSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_tri_ucs_romania\", tridirectional_search)\n",
    "TestTriSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_tri_ucs_romania\", tridirectional_search)\n",
    "TestTriSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_tri_ucs_romania\", tridirectional_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d5aea",
   "metadata": {},
   "source": [
    "### Exercise 4: Upgraded Tridirectional search (8 Pts) <a name=\"tri-upgraded\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c378e14b",
   "metadata": {},
   "source": [
    "This is the heart of the assignment. Implement tridirectional search in such a way as to consistently improve on the\n",
    "performance of your previous implementation. This means consistently exploring fewer nodes during your search in order\n",
    "to reduce runtime. Keep in mind, we are not performing 3 bidirectional A* searches. We are searching from each of the goals towards the other two goals, in the direction that seems most promising.\n",
    "\n",
    "The specifics are up to you, but we have a few suggestions:\n",
    " * Tridirectional A*\n",
    " * choosing landmarks and pre-computing reach values\n",
    " * ATL (A\\*, landmarks, and triangle-inequality)\n",
    " * shortcuts (skipping nodes with low reach values)\n",
    "\n",
    "`tridirectional_upgraded()` should return a path between all three nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516cfea",
   "metadata": {},
   "source": [
    "> **Requirements**\n",
    "> 1. Implement the `tridirectional_upgraded()` method below. Optionally, you can also implement `compute_landmarks()` and `custom_heuristic()`, but neither of them are absolutely necessary to receive full marks on this exercise.\n",
    "> 2. If all three goals are the same, simply return an empty list like `[]`.\n",
    "> 3. If there are 2 identical goals (i.e. `[a,b,b]`) then return the path `[a...b]` (i.e. just the path from `a` to `b`). Do **NOT** call your bidirectional searches for this, your tridirectional search should naturally handle this scenario.\n",
    "> 4. Return the best path found as a Python list connecting all three goal nodes (inclusive).\n",
    "> 5. You can obtain a dictionary of the neighbors of a node by calling `graph.neighbors(node)`.\n",
    "> 6. Sort the neighbors of a node alphabetically before processing them.\n",
    "> 7. You can access the edge weight between two nodes `u` and `v` by using `graph.get_edge_weight(u, v)`.\n",
    "> 8. Make sure no node is explored more than once, regardless of which frontier explored it.\n",
    "> 9. We provide a small margin of error for your explored count when grading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b653920",
   "metadata": {},
   "source": [
    "> **Hints**\n",
    "> 1. **What makes tridirectional A* different from tridirectional UCS?** Well for starters, A* uses heuristics to accelerate the exploration process. While the Euclidean heuristic is still available, there are new two goals for every search that is expanding, which means there will be two heuristic values. Which one should you choose? Could we combine them? Its time to get creative!\n",
    "> 2. **What are Landmarks/Reaches/Shortcuts?** Cool stuff! Checkout the textbook and the provided resources, they are definitely worth reading.\n",
    "> 3. **How does `compute_landmarks` work?** Seeing a lot of concern over this, `compute_landmarks` is optional and is a pre-processing function where we pass you the test graph and you can compute landmark information for it. The return value is a `list` of **four** elements, and each element is suggested to contain an identifier for what that landmark is along with a map/dictionary kind of thing that contains information about each node's true path cost to that landmark. We will first call your `compute_landmarks` function to get your landmarks, then we will reset the graph (so that your `compute_landmarks` function doesn’t blow up your explored count) then we call your tridirectional function and pass in your landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf76c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def compute_landmarks(graph):\n",
    "    \"\"\"\n",
    "    (Optional)\n",
    "    Feel free to implement this method for computing landmarks. We will call\n",
    "    tridirectional_upgraded() with the object returned from this function.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "\n",
    "    Returns:\n",
    "    List with not more than 4 computed landmarks. \n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    return None\n",
    "\n",
    "\n",
    "def custom_heuristic(graph, u, v):\n",
    "    \"\"\"\n",
    "        Feel free to use this method to try and work with different heuristics and come up with a better search algorithm.\n",
    "        Args:\n",
    "            graph (ExplorableGraph): Undirected graph to search.\n",
    "            u (str): Key for the first node to calculate from.\n",
    "            v (str): Key for the second node to calculate to.\n",
    "        Returns:\n",
    "            Custom heuristic distance between `v` node and `goal` node\n",
    "        \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def tridirectional_upgraded(graph, goals, heuristic=euclidean_dist_heuristic, landmarks=None):\n",
    "    \"\"\"\n",
    "    Exercise 4: Upgraded Tridirectional Search\n",
    "\n",
    "    See README.MD for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        goals (list): Key values for the 3 goals\n",
    "        heuristic: Function to determine distance heuristic.\n",
    "            Default: euclidean_dist_heuristic.\n",
    "        landmarks: Iterable containing landmarks pre-computed in compute_landmarks()\n",
    "            Default: None\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from one of the goal nodes (including both of\n",
    "        the other goal nodes).\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a257867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestTriSearchAlgorithms\n",
    "\n",
    "landmarks = TestTriSearchAlgorithms(\"get_landmarks\").get_landmarks(compute_landmarks)\n",
    "TestTriSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_tri_upgraded_romania\", tridirectional_upgraded, heuristic=euclidean_dist_heuristic, landmarks=landmarks)\n",
    "TestTriSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_tri_upgraded_romania\", tridirectional_upgraded, heuristic=euclidean_dist_heuristic, landmarks=landmarks)\n",
    "TestTriSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_tri_upgraded_romania\", tridirectional_upgraded, heuristic=euclidean_dist_heuristic, landmarks=landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658aae4",
   "metadata": {},
   "source": [
    "## Extra Credit - The Race <a name=\"race\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b3a610",
   "metadata": {},
   "source": [
    "Here's your chance to show us your best stuff. This is a **two goal search** on the **Atlanta** map. It is a race, so there is a leaderboard on Gradescope that will help determine who gets how many extra credit points.\n",
    "\n",
    "To participate in the leaderboard, implement `custom_search()` using whatever strategy you like. Recognize that this is optional and for extra credit and is not needed for the regular A1 submission (in fact it is a whole separate Gradescope submission with a separate deadline).\n",
    "\n",
    "**Specific details will be posted soon on Edstem.**\n",
    "\n",
    "**Bonus points are added to the grade for this assignment, not to your overall grade.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37040c",
   "metadata": {},
   "source": [
    "We have included the \"Haversine\" heuristic below. All of the local tests on the Atlanta map use this method. For the race, you can use whatever you choose, but know that the Atlanta map positions are (latitude, longitude). If you would like to learn more about this formula, here is a link: https://en.wikipedia.org/wiki/Haversine_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def haversine_dist_heuristic(graph, v, goal):\n",
    "    \"\"\"\n",
    "    Note: This provided heuristic is for the Atlanta race.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        v (str): Key for the node to calculate from.\n",
    "        goal (str): Key for the end node to calculate to.\n",
    "\n",
    "    Returns:\n",
    "        Haversine distance between `v` node and `goal` node\n",
    "    \"\"\"\n",
    "\n",
    "    #Load latitude and longitude coordinates in radians:͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    vLatLong = (math.radians(graph.nodes[v][\"pos\"][0]), math.radians(graph.nodes[v][\"pos\"][1]))\n",
    "    goalLatLong = (math.radians(graph.nodes[goal][\"pos\"][0]), math.radians(graph.nodes[goal][\"pos\"][1]))\n",
    "\n",
    "    #Now we want to execute portions of the formula:͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    constOutFront = 2*6371 #Radius of Earth is 6,371 kilometers\n",
    "    term1InSqrt = (math.sin((goalLatLong[0]-vLatLong[0])/2))**2 #First term inside sqrt\n",
    "    term2InSqrt = math.cos(vLatLong[0])*math.cos(goalLatLong[0])*((math.sin((goalLatLong[1]-vLatLong[1])/2))**2) #Second term\n",
    "    return constOutFront*math.asin(math.sqrt(term1InSqrt+term2InSqrt)) #Straight application of formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def load_data(graph, time_left):\n",
    "    \"\"\"\n",
    "    Feel free to implement this method. We'll call it only once \n",
    "    at the beginning of the Race, and we'll pass the output to your custom_search function.\n",
    "    graph: a networkx graph\n",
    "    time_left: function you can call to keep track of your remaining time.\n",
    "        usage: time_left() returns the time left in milliseconds.\n",
    "        the max time will be 10 minutes.\n",
    "\n",
    "    * To get a list of nodes, use graph.nodes()\n",
    "    * To get node neighbors, use graph.neighbors(node)\n",
    "    * To get edge weight, use graph.get_edge_weight(node1, node2)\n",
    "    \"\"\"\n",
    "\n",
    "    # nodes = graph.nodes()͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def custom_search(graph, start, goal, data=None):\n",
    "    \"\"\"\n",
    "    Race!: Implement your best search algorithm here to compete against the\n",
    "    other student agents.\n",
    "\n",
    "    If you implement this function and submit your code to Gradescope, you'll be\n",
    "    registered for the Race!\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "        data :  Data used in the custom search.\n",
    "            Will be passed your data from load_data(graph).\n",
    "            Default: None.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: finish this function!͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "    raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
