{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0cd3e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Search Algortihms\n",
    "\n",
    "To best understand an algorithm, build it. \n",
    "\n",
    "Search is an integral part of AI. It helps in problem solving across a wide variety of domains where a solution isn’t immediately clear. The Breadth First Search algortihm, A\\* and Djikstra's are popular search algortihms, however their implementation is non-trivial. This certainly holds tru for optimal bi-directional and tri-directional search problems. With that in mind and to really appreciate the usage of libraries for search algorithms I will implement several graph search algorithms from scratch with the goal of ultimately designing an algorithm that can solve tri-directional search problems while achieving minimal node exploration count.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047fee8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Disclaimer and Copyright Notice\n",
    "\n",
    "All functional implementations presented in this report have been independently developed by me, Franz Adam. If code or methodology, especially around my tri-directional UCS search algorithm, is used please reference me accoridngly. Since some of the code and solution presented in this report might overlap with graduate CS univeristy courses, I advise current students to adhere to their academic institution's policies regarding integrity and plagiarism before continuing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338663c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Search Graph \n",
    "\n",
    "As inspiration from Peter Norvigs famous textbook, Artificial Intelligence, I ran, traced and tested my search algorithms to calculate a route between two points in Romania while seeking to minimize time and space cost. \n",
    "\n",
    "Additionally, since the Romania graph is relatively small, I utilized an additional graph of Atlanta with many more nodes for further testing. \n",
    "![romania.png](images/romania.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a47653",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "import os\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73874d42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Priority Queue\n",
    "\n",
    "In all searches that involve calculating path cost or heuristic (e.g. uniform-cost), we have to order our search frontier. It turns out the way that we do this can impact our overall search runtime. To show this, I will implement a priority queue which will help in understanding its performance benefits. For large graphs, sorting all input to a priority queue is impractical. As such, the data structure I implement will have an **amortized O(1) insertion and O(lg n) removal time**. For the purposes of this project, I treat **smaller values as values with higher priority**. For example a value of 1 has a higher priority than a value of 2.\n",
    "\n",
    "\n",
    "#### Mathematical Overview:\n",
    "\n",
    "A priority queue, denoted as $Q$, operates by inserting nodes $n$ with an associated priority. The operation can be defined as:\n",
    "\n",
    "$$Q.insert(n, priority)$$\n",
    "\n",
    "In the context of search algorithms, the priority typically depends on the cost $g(n)$ or the evaluation function $f(n) = g(n) + h(n)$, where $h(n)$ is the heuristic.\n",
    "\n",
    "#### Implementation Details:\n",
    "\n",
    "The priority queue was implemented using a binary heap to efficiently support the operations required for the search algorithms, particularly the extract-min operation, which is critical for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a80f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Properties**\n",
    "1. Amortized O(1) insertion and O(log n) removal. \n",
    "2. Preserve FIFO. It is possible for the priority queue to receive two elements with the same priority. In the event that that occurs, the element that joined the priority queue first should be returned first.\n",
    "3. Generalize. The nodes provided to the priority queue will be Python tuples in the form of `(priority, payload)`. We assume that the datatype for `priority` is a standard Python datatype (i.e. `int`, `float`, `str`, etc.). The `payload` can be of any datatype (standard or custom).\n",
    "4. It is possible for duplicate nodes to enter the queue. (i.e. identical priority, identical payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53c42571",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class PriorityQueue(object):\n",
    "    \"\"\"\n",
    "    A queue structure where each element is served in order of priority.\n",
    "\n",
    "    Elements in the queue are popped based on the priority with higher priority\n",
    "    elements being served before lower priority elements.  If two elements have\n",
    "    the same priority, they will be served in the order they were added to the\n",
    "    queue.\n",
    "\n",
    "    Traditionally priority queues are implemented with heaps, but there are any\n",
    "    number of implementation options.\n",
    "\n",
    "    (Hint: take a look at the module heapq)\n",
    "\n",
    "    Attributes:\n",
    "        queue (list): Nodes added to the priority queue.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a new Priority Queue.\"\"\"\n",
    "\n",
    "        self.queue = []\n",
    "        self.counter = 0\n",
    "\n",
    "    def pop(self):\n",
    "       \n",
    "        \"\"\"\n",
    "        Pop the top priority node from the queue.\n",
    "\n",
    "        Returns:\n",
    "        The node with the highest priority.\n",
    "        \"\"\"\n",
    "        if self.size() == 0: #Check for empty\n",
    "            raise IndexError(\"There are no items in the queue.\")\n",
    "        \n",
    "        elif self.size() == 1: #I hardcoded this base case to simplify the implementation\n",
    "            return_node = self.queue[0]\n",
    "            self.queue.pop(0)\n",
    "        \n",
    "        else: \n",
    "            return_node = self.queue[0]\n",
    "            self.queue[0], heapify_index = self.queue[-1], 0 #Swap last and first item and then heapify it downwards\n",
    "            self.queue.pop(-1) #Delete/Pop the last item \n",
    "        \n",
    "            index_left_child = heapify_index * 2 + 1 #Set up child indixes for heapified node\n",
    "            index_right_child = heapify_index * 2 + 2\n",
    "        \n",
    "            #While left or right children exist to potentially swap\n",
    "            while index_left_child < self.size() or index_right_child < self.size(): \n",
    "                smallest = heapify_index\n",
    "\n",
    "                #If left child exists and < than heapified node or if == same and counter is smaller, set smallest to left child\n",
    "                if index_left_child < self.size() and ((self.queue[index_left_child][0] < self.queue[smallest][0]) \n",
    "                                                       or ((self.queue[index_left_child][0] == self.queue[smallest][0]) \n",
    "                                                           and (self.queue[index_left_child][1] < self.queue[smallest][1]))):\n",
    "                    smallest = index_left_child\n",
    "                #Same for the right\n",
    "                if index_right_child < self.size() and ((self.queue[index_right_child][0] < self.queue[smallest][0]) \n",
    "                                                       or ((self.queue[index_right_child][0] == self.queue[smallest][0]) \n",
    "                                                           and (self.queue[index_right_child][1] < self.queue[smallest][1]))):\n",
    "                    smallest = index_right_child\n",
    "\n",
    "                if smallest == heapify_index: #Break if heapified node \n",
    "                    break\n",
    "\n",
    "                # Swap with the smallest child\n",
    "                self.queue[heapify_index], self.queue[smallest] = self.queue[smallest], self.queue[heapify_index]\n",
    "                heapify_index = smallest\n",
    "\n",
    "                index_left_child = heapify_index * 2 + 1\n",
    "                index_right_child = heapify_index * 2 + 2\n",
    "\n",
    "        return (return_node[0], return_node[2])\n",
    "        \n",
    "    def update(self, node, updated_priority):\n",
    "        \"\"\"\n",
    "        Updates priority value of queue for A* and UCS to a smaller value if found in A*\n",
    "        Loops through and updates. \n",
    "        \"\"\"\n",
    "        loop = True\n",
    "        \n",
    "        for i in range(len(self.queue)):\n",
    "            \n",
    "            if (self.queue[i][2] == node) and (loop == True):\n",
    "                #current = node\n",
    "                self.queue[i][0] = updated_priority\n",
    "                \n",
    "                if i != 0:\n",
    "                    current_index = i\n",
    "                    parent_index = int((current_index - 1) // 2)\n",
    "                \n",
    "                    #Heapfiy up\n",
    "                    while (((self.queue[current_index][0] < \n",
    "                           self.queue[parent_index][0]) or (self.queue[current_index][0] == \n",
    "                           self.queue[parent_index][0] and self.queue[current_index][1] < \n",
    "                           self.queue[parent_index][1])) and (current_index != 0)):\n",
    "                    \n",
    "                        temp = self.queue[current_index]\n",
    "                        self.queue[current_index] = self.queue[parent_index]\n",
    "                        self.queue[parent_index] = temp\n",
    "                           \n",
    "                        #update current and parent index\n",
    "                        current_index = parent_index\n",
    "                        if current_index != 0:\n",
    "                           parent_index = int((parent_index - 1) // 2)\n",
    "                           \n",
    "                    loop = False\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Queue iterator.\"\"\"\n",
    "\n",
    "        return iter(sorted(self.queue))\n",
    "\n",
    "    def append(self, node):\n",
    "        \"\"\"\n",
    "        Append a node to the queue.\n",
    "\n",
    "        Args:\n",
    "            node: Comparable Object to be added to the priority queue.\n",
    "        \n",
    "        I am building a min-heap as implementation. I conserve the min-heap property by heapifying every new node \n",
    "        as long as it's smaller than it's parent.\n",
    "        \"\"\"\n",
    "        #Restructure the tuple into a list to keep track of insertion order\n",
    "        node_list = []\n",
    "        node_list.append(node[0])\n",
    "        node_list.append(self.counter)\n",
    "        node_list.append(node[1])\n",
    "        self.counter = self.counter + 1\n",
    "        \n",
    "        if self.size() == 0:\n",
    "            self.queue.append(node_list)\n",
    "        else: \n",
    "            self.queue.append(node_list)\n",
    "            new_node_index = self.size() - 1\n",
    "            parent_index = int((new_node_index - 1) // 2)\n",
    "            \n",
    "            while((parent_index >= 0 and (node_list[0] < self.queue[parent_index][0])) \n",
    "                  or (node_list[0] == self.queue[parent_index][0] \n",
    "                      and node_list[1] < self.queue[parent_index][1])): #Heapify, while parent is bigger than inserted node, swap them\n",
    "                \n",
    "                temp_parent_node = self.queue[parent_index]\n",
    "                self.queue[parent_index] = node_list\n",
    "                self.queue[new_node_index] = temp_parent_node\n",
    "                new_node_index = parent_index\n",
    "                parent_index = int((parent_index -1) // 2) #Will reach -1 if new node has lowest priority, adding and conditional\n",
    "            \n",
    "        return \"Append Successful\"\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        \"\"\"\n",
    "        Containment Check operator for 'in'\n",
    "\n",
    "        Args:\n",
    "            key: The key to check for in the queue.\n",
    "\n",
    "        Returns:\n",
    "            True if key is found in queue, False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        return key in [n[-1] for n in self.queue]\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Compare this Priority Queue with another Priority Queue.\n",
    "\n",
    "        Args:\n",
    "            other (PriorityQueue): Priority Queue to compare against.\n",
    "\n",
    "        Returns:\n",
    "            True if the two priority queues are equivalent.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.queue == other.queue\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"\n",
    "        Get the current size of the queue.\n",
    "\n",
    "        Returns:\n",
    "            Integer of number of items in queue.\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.queue)\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Reset queue to empty (no nodes).\"\"\"\n",
    "\n",
    "        self.queue = []\n",
    "\n",
    "    def top(self):\n",
    "        \"\"\"\n",
    "        Get the top item in the queue.\n",
    "\n",
    "        Returns:\n",
    "            The first item stored in the queue.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.queue[0]\n",
    "    \n",
    "    def get_nodes(self):\n",
    "        nodes = []\n",
    "        for i in range(len(self.queue)):\n",
    "            nodes.append(self.queue[i][2])\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f27b2e0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_append_and_pop\"!\n",
      "UnitTest passed successfully for \"test_fifo_property\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestPriorityQueue\n",
    "\n",
    "TestPriorityQueue(\"test_append_and_pop\").test_append_and_pop(PriorityQueue)\n",
    "TestPriorityQueue(\"test_fifo_property\").test_fifo_property(PriorityQueue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2f352",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Breadth First Search\n",
    "\n",
    "Breadth-First Search (BFS) is a foundational algorithm in computer science used to explore the nodes of a graph or tree structure systematically. It is particularly effective in scenarios where a solution or target node is expected to be closer to the root, as it explores all nodes at the present depth level before moving on to nodes at the next depth level.\n",
    "\n",
    "#### Overview:\n",
    "\n",
    "BFS operates with the underlying function:\n",
    "\n",
    "$$f(n) = g(n)$$\n",
    "\n",
    "Here, $f(n)$ represents the expansion priority of node $n$, and $g(n)$ quantifies the depth of node $n$ from the start node, counting the number of edges traversed. In BFS, all edges are considered to have equal weight, and nodes are explored based on their distance from the root node. This distance is effectively the shortest path in an unweighted graph when considering path cost purely in terms of the number of edges traversed.\n",
    "\n",
    "#### BFS Algorithm Details:\n",
    "\n",
    "1. **Initialization**: BFS begins at a specified root node and explores its neighbors first. It employs a queue data structure to manage the sequence of nodes explored, ensuring that nodes are expanded in the order they are discovered.\n",
    "   \n",
    "2. **Node Expansion**: Nodes are dequeued and their adjacent nodes are enqueued, if they have not been visited already. This step is repeated until the queue is empty or the goal is found. Each node is typically marked as visited to avoid revisiting and looping.\n",
    "\n",
    "3. **Path Recovery**: To reconstruct the path from the start node to the goal, BFS can be modified to track the predecessor of each visited node. Once the goal node is found, the path can be easily reconstructed by following the predecessors from the goal node back to the start node.\n",
    "\n",
    "4. **Complexity**: The time complexity of BFS is $O(V + E)$, where $V$ is the number of vertices and $E$ is the number of edges in the graph. The space complexity is also $O(V)$, as it needs to store all vertex states and the queue.\n",
    "\n",
    "#### Completeness and Optimality\n",
    "\n",
    "- **Completeness**: BFS is complete, meaning that it will find a solution if at least one exists. This property is crucial in scenarios where all possible states must be explored to find a solution, such as puzzles or finding any path in a maze.\n",
    "\n",
    "- **Optimality**: When all edges have the same weight, BFS is also optimal. This means that the first time a goal node is reached, the path to it is the shortest possible in terms of the number of edges traversed. In scenarios where paths have different costs, BFS would not guarantee the least costly path unless all costs are equal.\n",
    "\n",
    "#### Applications\n",
    "\n",
    "BFS is widely used in situations requiring the exploration of all possible scenarios to a certain depth, pathfinding algorithms in simple maps, networking routines like broadcast protocols, and in the analysis of social networking graphs to find all entities within one connected component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9975558",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def breadth_first_search(graph, start, goal):\n",
    "    \"\"\"\n",
    "    Implement breadth-first-search.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "\n",
    "    if start == goal: return []\n",
    "    \n",
    "    bfs_queue = [start]\n",
    "    visited = set()\n",
    "    parent_dir = {start: None}\n",
    "    path = []\n",
    "    \n",
    "    while len(bfs_queue) > 0:\n",
    "        current = bfs_queue.pop(0)\n",
    "\n",
    "        if current == goal:\n",
    "            #path = []\n",
    "            while current is not None:\n",
    "                path.insert(0, current)\n",
    "                current = parent_dir[current]\n",
    "            return path\n",
    "        \n",
    "        temp_list = []\n",
    "        \n",
    "        for neighbor in graph.neighbors(current):\n",
    "            if neighbor not in visited and neighbor not in parent_dir:\n",
    "                \n",
    "                if neighbor == goal:\n",
    "                    parent_dir[neighbor] = current\n",
    "                    current = neighbor\n",
    "                    while current is not None:\n",
    "                        path.insert(0, current)\n",
    "                        current = parent_dir[current]\n",
    "                    return path\n",
    "                    \n",
    "                parent_dir[neighbor] = current\n",
    "                temp_list.append(neighbor)\n",
    "        \n",
    "        temp_list = sorted(temp_list)\n",
    "        \n",
    "        for node in temp_list:\n",
    "            bfs_queue.append(node)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c18435",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestBFS\n",
    "\n",
    "TestBFS(\"test_valid_paths\").test_valid_paths(breadth_first_search)\n",
    "TestBFS(\"test_optimal_paths\").test_optimal_paths(breadth_first_search)\n",
    "TestBFS(\"test_explored_counts\").test_explored_counts(breadth_first_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef72bfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uniform-cost search\n",
    "\n",
    "Uniform Cost Search (UCS) is a more generalized form of Breadth-First Search that deals effectively with graphs where edges have varying costs. It prioritizes expanding the least costly paths first, making it particularly suitable for finding the shortest path in weighted graphs where costs between nodes vary.\n",
    "\n",
    "#### Technical and Mathematical Details\n",
    "\n",
    "UCS expands paths in order of increasing path cost. This strategy ensures that when a goal node is first reached, the path to it is guaranteed to be optimal with respect to the cost function used. This optimality and completeness are significant advantages of UCS, especially in complex and variable-cost environments.\n",
    "\n",
    "#### Mathematical Overview:\n",
    "\n",
    "The key function governing UCS is: $f(n) = g(n)$\n",
    "\n",
    "where:\n",
    "- $f(n)$ is the total cost of the path from the start node to node $n$,\n",
    "- $g(n)$ is the cost from the start node to node $n$.\n",
    "\n",
    "Unlike BFS, which assumes all path costs are equal, UCS extends this by allowing diverse and dynamic costs. It uses a priority queue (often implemented with a min-heap) to manage the expansion of nodes, ensuring that nodes with the lowest path cost are selected for expansion first.\n",
    "\n",
    "#### Completeness and Optimality\n",
    "\n",
    "- **Completeness**: UCS is complete, meaning it will always find a solution if one exists, as long as the cost of each step exceeds some small positive constant $ \\epsilon $ (to prevent infinite loops).\n",
    "  \n",
    "- **Optimality**: The strategy is also optimal, guaranteeing that the first solution found is the least costly among all solutions. This optimality holds under the condition that the step costs are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0f41f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def uniform_cost_search(graph, start, goal):\n",
    "    \"\"\"\n",
    "    Uniform_cost_search.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    #Check if start == goal, and if return []\n",
    "    if start == goal:\n",
    "        return []\n",
    "    \n",
    "    #Assign priority queue and add start as first element (root) with priority of 0\n",
    "    priority_q = PriorityQueue()\n",
    "    start_tuple = (0, start)\n",
    "    priority_q.append(start_tuple)\n",
    "    visited = set()\n",
    "    parent_dir = {start: [\"stop\", 0]}\n",
    "    path = []\n",
    "    \n",
    "    #While top in our priority queue is not equal to the goal node\n",
    "    while (priority_q.top()[2] != goal):\n",
    "        \n",
    "        #Assign current node that is being explored, pop it off the priority queue\n",
    "        #Initialize temporary list = []\n",
    "        current = priority_q.pop()\n",
    "        temp_list = []\n",
    "        \n",
    "        #Loop through neighbors of current that are not in visited\n",
    "        for neighbor in graph.neighbors(current[1]):\n",
    "            \n",
    "            #Save them to a temporary list of tuples with \n",
    "            #edge cost from current to neighbor + total edge cost to current\n",
    "            \n",
    "            if neighbor not in visited:\n",
    "                \n",
    "                total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parent_dir[current[1]][1]\n",
    "                #Make current the parent of neighbor if not in parent_dir or smaller than existing entry\n",
    "                if neighbor not in parent_dir:\n",
    "                    \n",
    "                    #Make current the parent of neighbor\n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    temp_cost = total_edge_cost\n",
    "                    temp_list.append((temp_cost, neighbor))\n",
    "                    \n",
    "                elif total_edge_cost < parent_dir[neighbor][1]:\n",
    "                    \n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    #edge_diff = parent_dir[neighbor][1] - total_edge_cost\n",
    "                    priority_q.update(neighbor, total_edge_cost)\n",
    "        \n",
    "        #Mark current as visited \n",
    "        visited.add(current[1])\n",
    "        \n",
    "        sort_and_append(priority_q, temp_list)\n",
    "        #Sort the list alphabetically based on their tuple[1] value which will be a single character type string\n",
    "        #sorted_tuples = sorted(temp_list, key=lambda x: x[1])\n",
    "        \n",
    "        #Append the list values to the priority queue, which will handle the prioritization\n",
    "        #for element in sorted_tuples:\n",
    "            #priority_q.append(element)\n",
    "            \n",
    "        #If top of priority queue == goal\n",
    "        #backtrack from goal node to start using parent_directory and build path, return path\n",
    "        if priority_q.top()[2] == goal:\n",
    "            back_track = goal\n",
    "            \n",
    "            while back_track != \"stop\":\n",
    "                path.insert(0, back_track)\n",
    "                back_track = parent_dir[back_track][0]\n",
    "                \n",
    "            return path\n",
    "    \n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae71e0b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_ucs_romania\", uniform_cost_search)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_ucs_romania\", uniform_cost_search)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_ucs_romania\", uniform_cost_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96268402",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A* search\n",
    "\n",
    "A* Search is a powerful and widely used pathfinding and graph traversal algorithm that efficiently finds the shortest path from a start node to a goal node while minimizing the total cost (usually distance, time, or other resource). It extends Dijkstra's algorithm by using heuristics to estimate the cost from a node to the goal, which significantly speeds up the search process in large graphs by pruning paths that are unlikely to lead to the optimal solution.\n",
    "\n",
    "#### Technical and Mathematical Details\n",
    "\n",
    "A* search uses the following function to determine the order of node expansion:\n",
    "\n",
    "$$f(n) = g(n) + h(n)$$\n",
    "\n",
    "where:\n",
    "- \\(f(n)\\) is the total estimated cost of the cheapest solution through node \\(n\\).\n",
    "- \\(g(n)\\) is the cost from the start node to node \\(n\\), which is known.\n",
    "- \\(h(n)\\) is a heuristic function estimating the lowest cost from node \\(n\\) to the goal.\n",
    "\n",
    "#### Completeness and Optimality\n",
    "\n",
    "- **Completeness**: A* is complete, meaning it will always find a solution if one exists, provided that the number of nodes in the graph is finite and the cost of moving between nodes is bounded by a positive constant.\n",
    "  \n",
    "- **Optimality**: A* is optimal if the heuristic function \\(h(n)\\) is admissible, meaning it never overestimates the actual cost to reach the nearest goal node from \\(n\\). Under these conditions, A* not only finds a solution, but it finds the optimal solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329ff68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Heuristic\n",
    "\n",
    "For this implementation we'll be using the euclidean distance as heuristic to evaluate the distance from a node to the goal. The Euclidean distance metric is admissible when used as a heuristic in the A* search algorithm for problems where it represents the straight-line distance between the current node and the goal in a real-world layout, such as points on a map. This is because it never overestimates the actual shortest path cost between two points, adhering to the triangle inequality in metric spaces, thus ensuring that the heuristic is optimistic and guarantees the optimality of the A* search.\n",
    "\n",
    "```python\n",
    "def euclidean_dist_heuristic(graph, u, v):\n",
    "    \"\"\"\n",
    "    Euclidean distance heuristic.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        u (str): Key for the first node to calculate from.\n",
    "        v (str): Key for the second node to calculate to.\n",
    "\n",
    "    Returns:\n",
    "        Euclidean distance between the `u` node and the `v` node\n",
    "        Round the result to 3 decimal places (if applicable)\n",
    "    \"\"\"\n",
    "\n",
    "    x_diff = graph.nodes[u]['pos'][0] - graph.nodes[v]['pos'][0]\n",
    "    y_diff = graph.nodes[u]['pos'][1] - graph.nodes[v]['pos'][1]\n",
    "\n",
    "    return round(math.sqrt(x_diff**2 + y_diff**2), 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b9331c2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_dist_heuristic(graph, u, v):\n",
    "    \"\"\"\n",
    "    Euclidean distance heuristic.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        u (str): Key for the first node to calculate from.\n",
    "        v (str): Key for the second node to calculate to.\n",
    "\n",
    "    Returns:\n",
    "        Euclidean distance between the `u` node and the `v` node\n",
    "        Round the result to 3 decimal places (if applicable)\n",
    "    \"\"\"\n",
    "    \n",
    "    x_diff = graph.nodes[u]['pos'][0] - graph.nodes[v]['pos'][0]\n",
    "    y_diff = graph.nodes[u]['pos'][1] - graph.nodes[v]['pos'][1]\n",
    "    \n",
    "    return round(math.sqrt(x_diff**2 + y_diff**2), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e462bdd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_euclidean_distance\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestEuclideanHeuristic\n",
    "\n",
    "TestEuclideanHeuristic(\"test_euclidean_distance\").test_euclidean_distance(euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edd7eb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### A* Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1427267",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def a_star(graph, start, goal, heuristic=euclidean_dist_heuristic):\n",
    "    \"\"\"\n",
    "    Warm-up exercise: Implement A* algorithm.\n",
    "\n",
    "    See README.md for exercise description.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "        heuristic: Function to determine distance heuristic.\n",
    "            Default: euclidean_dist_heuristic.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    \n",
    "    #Check if start == goal, and if return []\n",
    "    if start == goal:\n",
    "        return []\n",
    "    \n",
    "    #Assign priority queue and add start as first element (root) with priority of 0 + euclidean distance to goal (heuristic)\n",
    "    priority_q = PriorityQueue()\n",
    "    start_tuple = (heuristic(graph, start, goal), start)\n",
    "    priority_q.append(start_tuple)\n",
    "    visited = set()\n",
    "    parent_dir = {start: [\"stop\", 0]}\n",
    "    path = []\n",
    "    \n",
    "    #While top in our priority queue is not equal to the goal node\n",
    "    while (priority_q.top()[2] != goal):\n",
    "        \n",
    "        #Assign current node that is being explored, pop it off the priority queue\n",
    "        #Initialize temporary list = []\n",
    "        current = priority_q.pop()\n",
    "        temp_list = []\n",
    "        \n",
    "        #Loop through neighbors of current that are not in visited\n",
    "        for neighbor in graph.neighbors(current[1]):\n",
    "            \n",
    "            #Save them to a temporary list of tuples with \n",
    "            #(edge cost from current to neighbor + euclidean distance from neighbor to goal (heuristic), node)\n",
    "            \n",
    "            if neighbor not in visited:\n",
    "                \n",
    "                total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parent_dir[current[1]][1]\n",
    "                #Make current the parent of neighbor if not in parent_dir or smaller than existing entry\n",
    "                if neighbor not in parent_dir:\n",
    "                    \n",
    "                    #Make current the parent of neighbor\n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    temp_cost = total_edge_cost + heuristic(graph, neighbor, goal)\n",
    "                    temp_list.append((temp_cost, neighbor))\n",
    "                    \n",
    "                elif total_edge_cost < parent_dir[neighbor][1]:\n",
    "                    \n",
    "                    parent_dir[neighbor] = [current[1], total_edge_cost]\n",
    "                    \n",
    "                    #edge_diff = parent_dir[neighbor][1] - total_edge_cost\n",
    "                    priority_q.update(neighbor, total_edge_cost + heuristic(graph, neighbor, goal))\n",
    "        \n",
    "        #Mark current as visited \n",
    "        visited.add(current[1])\n",
    "        \n",
    "        #Sort the list alphabetically based on their tuple[1] value which will be a single character type string\n",
    "        sorted_tuples = sorted(temp_list, key=lambda x: x[1])\n",
    "        \n",
    "        #Append the list values to the priority queue, which will handle the prioritization\n",
    "        for element in sorted_tuples:\n",
    "            priority_q.append(element)\n",
    "            \n",
    "        #If top of priority queue == goal\n",
    "        #backtrack from goal node to start using parent_directory and build path, return path\n",
    "        if priority_q.top()[2] == goal:\n",
    "            back_track = goal\n",
    "            \n",
    "            while back_track != \"stop\":\n",
    "                path.insert(0, back_track)\n",
    "                back_track = parent_dir[back_track][0]\n",
    "                \n",
    "            return path\n",
    "        \n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afeab513",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_a_star_null_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_null_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_null_romania.test_explored_counts\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_a_star_euclidean_romania.test_explored_counts\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_a_star_null_romania\", a_star, heuristic=null_heuristic)\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_a_star_euclidean_romania\", a_star, heuristic=euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f2837",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bidirectional A* search \n",
    "\n",
    "Bi-directional A* conducts two synchronized A* searches, one from the start and another from the goal, which can significantly reduce the search space under certain conditions.\n",
    "\n",
    "#### Stopping Condition:\n",
    "\n",
    "This method uses two heuristics, $h_1(n)$ for the start-to-node heuristic and $h_2(n)$ for the goal-to-node heuristic. The searches meet effectively when:\n",
    "\n",
    "$$g_1(n) + g_2(n) \\geq f_{\\text{min}}$$\n",
    "\n",
    "where $g_1$ and $g_2$ are the costs from the start and goal to the node $n$ respectively, and $f_{\\text{min}}$ is the smallest path cost found.\n",
    "\n",
    "#### Ira Pohl's Contribution:\n",
    "\n",
    "Pohl introduced a refined stopping condition for bidirectional search, focusing on ensuring that the combined paths' cost from start and goal to a meeting point $n$ does not exceed the best known path cost. This is mathematically captured as:\n",
    "\n",
    "$$C(x) + C(y) - h(x, y) \\leq C(p)$$\n",
    "\n",
    "where $x$ and $y$ are nodes from the opposite ends of the search and $p$ is their meeting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "eaf8118d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def bidirectional_a_star(graph, start, goal,\n",
    "                         heuristic=euclidean_dist_heuristic):\n",
    "    \"\"\"\n",
    "    Bidirectional A*.\n",
    "\n",
    "    Args:\n",
    "        graph (ExplorableGraph): Undirected graph to search.\n",
    "        start (str): Key for the start node.\n",
    "        goal (str): Key for the end node.\n",
    "        heuristic: Function to determine distance heuristic.\n",
    "        Default: euclidean_dist_heuristic.\n",
    "\n",
    "    Returns:\n",
    "        The best path as a list from the start to the goal node (including both).\n",
    "    \"\"\"\n",
    "    #Start condition and initializations\n",
    "    if start == goal: return []\n",
    "\n",
    "    q_forward, q_backward = PriorityQueue(), PriorityQueue()\n",
    "    visited_f, visited_b = set(), set()\n",
    "    forward = True\n",
    "    q_forward.append((0, start))\n",
    "    q_backward.append((0, goal))\n",
    "    parents_f = {start: [\"stop\", 0]}\n",
    "    parents_b = {goal: [\"stop\", 0]}\n",
    "    \n",
    "    while (not visited_f.intersection(visited_b)): #while explored sets from forward and backward don't intersect\n",
    "        \n",
    "        if forward:   \n",
    "            current = q_forward.pop()\n",
    "            temp_list = []      \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in visited_f:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_f[current[1]][1]\n",
    "                    if neighbor not in parents_f: #If neighbor has no parent yet\n",
    "                        parents_f[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_cost = total_edge_cost + heuristic(graph, neighbor, goal)\n",
    "                        temp_list.append((temp_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_f[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_f[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q_forward.update(neighbor, temp_cost) #Update queue\n",
    "            \n",
    "            visited_f.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q_forward, temp_list) #Sort list alphabetically and append to forward queue\n",
    "            \n",
    "            forward = False\n",
    "        \n",
    "        #Backward \n",
    "        else: \n",
    "            current = q_backward.pop()\n",
    "            temp_list = []      \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in visited_b:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_b[current[1]][1]\n",
    "                    if neighbor not in parents_b: #If neighbor has no parent yet\n",
    "                        parents_b[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_cost = total_edge_cost + heuristic(graph, neighbor, start)\n",
    "                        temp_list.append((temp_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_b[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_b[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q_backward.update(neighbor, temp_cost) #Update queue\n",
    "            \n",
    "            visited_b.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q_backward, temp_list) #Sort list alphabetically and append to forward queue\n",
    "        \n",
    "            forward = True\n",
    "        \n",
    "    #As while loop stopped, explored sets intersect on one element\n",
    "    intersection_node = next(iter(visited_f.intersection(visited_b))) #Find intersection node\n",
    "    \n",
    "    crossover_points = list(visited_f.intersection(set((q_backward.get_nodes() + list(visited_b)))))\n",
    "\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, parents_b[point][1] + parents_f[point][1]])\n",
    "        \n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    path_costs = [sublist for sublist in path_costs if intersection_node != sublist[0]]\n",
    "    intersection_cost = parents_b[intersection_node][1] + parents_f[intersection_node][1]\n",
    "    \n",
    "    if intersection_cost > path_costs[0][1]:\n",
    "        \n",
    "        forward_path = backtrack_and_append(path_costs[0][0], parents_f)\n",
    "        backward_path = backtrack_and_append(path_costs[0][0], parents_b)\n",
    "    \n",
    "        backward_path = backward_path[:-1] #Remove last element\n",
    "        backward_path.reverse()\n",
    "    \n",
    "        path = forward_path + backward_path\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    \n",
    "    forward_path = backtrack_and_append(intersection_node, parents_f)\n",
    "    backward_path = backtrack_and_append(intersection_node, parents_b)\n",
    "    \n",
    "    backward_path = backward_path[:-1] #Remove last element\n",
    "    backward_path.reverse()\n",
    "    \n",
    "    path = forward_path + backward_path\n",
    "\n",
    "    return path\n",
    "   \n",
    "    \n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)\n",
    "\n",
    "def backtrack_and_append(intersection_node, parent_directory):\n",
    "    path = []\n",
    "    back_track = intersection_node\n",
    "    while back_track != \"stop\":\n",
    "        path.insert(0, back_track)\n",
    "        back_track = parent_directory[back_track][0]\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "db86f393",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_null_romania.test_explored_counts\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_valid_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_optimal_paths\"!\n",
      "UnitTest passed successfully for \"test_bi_a_star_euclidean_romania.test_explored_counts\"!\n"
     ]
    }
   ],
   "source": [
    "# Local tests͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "from utilities.localtests import TestSearchAlgorithms\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_bi_a_star_null_romania\", bidirectional_a_star, heuristic=null_heuristic)\n",
    "\n",
    "TestSearchAlgorithms(\"test_valid_paths\").test_valid_paths(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_optimal_paths\").test_optimal_paths(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)\n",
    "TestSearchAlgorithms(\"test_explored_counts\").test_explored_counts(\"test_bi_a_star_euclidean_romania\", bidirectional_a_star, heuristic=euclidean_dist_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac6e89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tri-directional UCS search \n",
    "\n",
    "The Tri-Directional Search algorithm is an enhanced variant of pathfinding algorithms, designed to optimize node exploration by simultaneously initiating searches from three strategically chosen nodes—commonly the start, goal, and an intermediary node which acts as an additional source or target. This approach is predicated on minimizing the explored search space more efficiently than bi-directional search, potentially halving the exploration overhead under optimal conditions.\n",
    "\n",
    "Tri-directional search leverages the theoretical framework of graph traversal to expedite convergence towards a solution by initiating multiple frontiers of exploration. Here, the graph is defined as G = (V, E) with V representing vertices and E representing edges. Each edge e connecting vertices u and v can optionally carry a weight w(u, v), which influences pathfinding in weighted scenarios.\n",
    "\n",
    "#### Optimization Objective:\n",
    "\n",
    "The core objective in the tri-directional approach is to minimize the total number of explored nodes, denoted as |N|, where N ⊆ V. This is achieved by optimizing the selection of the intermediary node and dynamically balancing the frontier expansion across the three nodes based on real-time heuristic evaluations.\n",
    "\n",
    "#### Search Dynamics:\n",
    "\n",
    "The search progresses through simultaneous expansion from three nodes using either BFS or DFS, potentially enhanced with heuristic functions akin to A*. For heuristic-driven searches, each node n in the frontier employs a cost function f(n) = g(n) + h(n), where:\n",
    "\n",
    "- g(n) is the exact cost path from the start to n,\n",
    "- h(n) is a heuristic estimate of the cost from n to the goal.\n",
    "\n",
    "In the tri-directional setup, this formulation is adapted for three interacting frontiers, necessitating a triplet of heuristic functions each tailored for path estimation from their respective origins to their destinations.\n",
    "\n",
    "#### Stopping Conditions\n",
    "\n",
    "The algorithm's termination is predicated on the convergence of the search frontiers, which can be theoretically articulated through the lens of optimal stopping conditions.\n",
    "\n",
    "##### Intersection-Based Stopping:\n",
    "\n",
    "The primary stopping criterion is the detection of an intersection among the sets of nodes explored by each frontier, denoted as S1, S2, and S3. Mathematically, the search can cease when:\n",
    "\n",
    "    S1 ∩ S2 ≠ ∅, or S1 ∩ S3 ≠ ∅, or S2 ∩ S3 ≠ ∅\n",
    "\n",
    "This condition ensures that a connecting path exists, albeit not necessarily the shortest.\n",
    "\n",
    "##### Cost-Based Stopping:\n",
    "\n",
    "Extending on Ira Pohl’s insights from bidirectional search, the optimal path guarantee can be framed as follows: if P is a path connecting the start to the goal, then the search can terminate when the summed minimal heuristic evaluations of any two fronts, plus the interconnecting path cost, exceed the best-known path cost:\n",
    "\n",
    "    min{f(x) | x ∈ Si} + min{f(y) | y ∈ Sj} + d(x, y) > C(P)\n",
    "\n",
    "where i, j ∈ {1, 2, 3}, i ≠ j, and d(x, y) represents the direct path cost between nodes x and y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "2910cc10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def tridirectional_search(graph, goals):\n",
    "    \n",
    "    ### SET UP \n",
    "    if goals[0] == goals[1] == goals[2]: return [] \n",
    "    #test = False\n",
    "    #if goals == ['b', 'm', 'o']:\n",
    "        #test = True\n",
    "    q1, q2, q3 = PriorityQueue(), PriorityQueue(), PriorityQueue()\n",
    "    v1, v2, v3 = set(), set(), set()\n",
    "    one, two, no_need_to_compare = True, True, False\n",
    "    \n",
    "    q1.append((0, goals[0]))\n",
    "    q2.append((0, goals[1]))\n",
    "    q3.append((0, goals[2]))\n",
    "\n",
    "    parents_1 = {goals[0]: [\"stop\", 0]}\n",
    "    parents_2 = {goals[1]: [\"stop\", 0]}\n",
    "    parents_3 = {goals[2]: [\"stop\", 0]}\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    ### INITIAL LOOP TO FIND FIRST INTERSECTION\n",
    "    \n",
    "    while ((q1.top()[2] not in v1.union(v2, v3)) and (q2.top()[2] not in v1.union(v2, v3)) and \n",
    "           (q3.top()[2] not in v1.union(v2, v3))):\n",
    "        \n",
    "        if one: #Search 1\n",
    "            current = q1.pop()\n",
    "            temp_list = []   \n",
    "            \n",
    "            \n",
    "            if q1.size() != 0:\n",
    "                if q1.top()[2] in v1.union(v2, v3):\n",
    "                    v1.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "            \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v1:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_1[current[1]][1]\n",
    "                    if neighbor not in parents_1: #If neighbor has no parent yet\n",
    "                        parents_1[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_1[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_1[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q1.update(neighbor, total_edge_cost) #Update queue \n",
    "            v1.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q1, temp_list) #Sort list alphabetically and append to queue\n",
    "            one = False\n",
    "        elif two: #Search 2 \n",
    "            current = q2.pop()\n",
    "            temp_list = []   \n",
    "            \n",
    "            if q2.size() != 0:\n",
    "                if q2.top()[2] in v1.union(v2, v3):\n",
    "                    v2.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "                    \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v2:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_2[current[1]][1]\n",
    "                    if neighbor not in parents_2: #If neighbor has no parent yet\n",
    "                        parents_2[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_2[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_2[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q2.update(neighbor, total_edge_cost) #Update queue\n",
    "            v2.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q2, temp_list) #Sort list alphabetically and append to queue\n",
    "            two = False\n",
    "        else: #Search 3 \n",
    "            current = q3.pop()\n",
    "            temp_list = []    \n",
    "            \n",
    "            if q3.size() != 0:\n",
    "                if q3.top()[2] in v1.union(v2, v3):\n",
    "                    v3.add(current[1]) #Add to forward set of visited\n",
    "                    break\n",
    "                    \n",
    "            for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "                if neighbor not in v3:\n",
    "                    total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_3[current[1]][1]\n",
    "                    if neighbor not in parents_3: #If neighbor has no parent yet\n",
    "                        parents_3[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                        temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "                    elif total_edge_cost < parents_3[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                        parents_3[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                        q3.update(neighbor, total_edge_cost) #Update queue\n",
    "            v3.add(current[1]) #Add to forward set of visited\n",
    "            sort_and_append(q3, temp_list) #Sort list alphabetically and append to queue\n",
    "            one = True \n",
    "            two = True     \n",
    "            \n",
    "    ####################################\n",
    "        \n",
    "    ### OPTIMIZE FIRST PATH AB\n",
    "    met = who_met_3(q1, q2, q3, v1, v2, v3, parents_1, parents_2, parents_3)\n",
    "    eval('v' + str(met[1])).add(met[0])\n",
    "    eval('v' + str(met[2])).add(met[0])\n",
    "    ab_intersect = met[0]\n",
    "    crossover_points = list(eval('v' + str(met[1])).intersection(set((eval('q' + str(met[2])).get_nodes() + \n",
    "                                                                             list(eval('v' + str(met[2])))))))\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, eval('parents_' + str(met[2]))[point][1] + \n",
    "                           eval('parents_' + str(met[1]))[point][1]])\n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    path_costs = [sublist for sublist in path_costs if ab_intersect != sublist[0]]\n",
    "    intersection_cost = eval('parents_' + str(met[2]))[met[0]][1] + eval('parents_' + str(met[1]))[met[0]][1]\n",
    "    if len(path_costs) != 0:\n",
    "        if intersection_cost > path_costs[0][1]:\n",
    "            ab_intersect = path_costs[0][0]\n",
    "            eval('v' + str(met[1])).add(ab_intersect)\n",
    "            eval('v' + str(met[2])).add(ab_intersect)\n",
    "    ab_path_cost = eval('parents_' + str(met[2]))[ab_intersect][1] + eval('parents_' + str(met[1]))[ab_intersect][1]\n",
    "    #####################################\n",
    "    \n",
    "    ### Continue Search with 3rd Search I\n",
    "    temp1, temp2 = [met[1], met[2]], ['1', '2','3']\n",
    "    result = [item for item in temp2 if item not in temp1] #result contains leftover search number\n",
    "    q_continue = eval('q' + str(result[0]))\n",
    "    parents_continue = eval('parents_' + str(result[0]))\n",
    "\n",
    "    while (q_continue.top()[2] not in eval('v' + str(met[1])).union(eval('v' + str(met[2])))):\n",
    "        current = q_continue.pop()\n",
    "        temp_list = [] \n",
    "        \"\"\"\n",
    "        if q_continue.size() != 0:\n",
    "            if q_continue.top()[2] in eval('v' + str(met[1])).union(eval('v' + str(met[2]))):\n",
    "                sort_and_append(q_continue, temp_list)\n",
    "                break\n",
    "         \"\"\"\n",
    "        for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "            total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_continue[current[1]][1]\n",
    "            if neighbor not in parents_continue: #If neighbor has no parent yet\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "            elif total_edge_cost < parents_continue[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                q_continue.update(neighbor, total_edge_cost) #Update queue               \n",
    "        sort_and_append(q_continue, temp_list) #Sort list alphabetically and append to queue\n",
    "        \n",
    "    #####################################\n",
    "    \n",
    "    ### OPTIMIZE SECOND PATH C - \n",
    "    c_search_x_initial = who_met_2(q_continue.top()[2], eval('v' + str(met[1])), met[1], eval('v' + str(met[2])), met[2])  \n",
    "    crossover_points = list(eval('v' + str(c_search_x_initial)).intersection(set((q_continue.get_nodes()))))\n",
    "    path_costs = []\n",
    "    for point in crossover_points:\n",
    "        path_costs.append([point, parents_continue[point][1] + eval('parents_' + str(c_search_x_initial))[point][1]])    \n",
    "    path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "    path_costs = [sublist for sublist in path_costs if q_continue.top()[2] != sublist[0]]\n",
    "    intersection_cost = parents_continue[q_continue.top()[2]][1] + eval('parents_' + str(c_search_x_initial))[q_continue.top()[2]][1]\n",
    "    intersect_node_c_x_initial = q_continue.top()[2]\n",
    "    if len(path_costs) != 0:\n",
    "        if intersection_cost > path_costs[0][1]:\n",
    "            intersect_node_c_x_initial = path_costs[0][0] #Update intersect node \n",
    "    c_x_path_cost_1 = parents_continue[intersect_node_c_x_initial][1] + eval('parents_' + str(c_search_x_initial))[intersect_node_c_x_initial][1]\n",
    "    \n",
    "    ######################################\n",
    "\n",
    "    ### Continue Search with 3rd Search II\n",
    "    options = [met[1], met[2]]\n",
    "    c_search_x_second = [item for item in options if item != c_search_x_initial][0]\n",
    "    \n",
    "    if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "        no_need_to_compare = True\n",
    "        \n",
    "    while (q_continue.top()[2] not in eval('v' + str(c_search_x_second))) and not no_need_to_compare:\n",
    "        if q_continue.size() == 1:\n",
    "            if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "                break\n",
    "                \n",
    "        current = q_continue.pop()\n",
    "        temp_list = []      \n",
    "        \n",
    "        if q_continue.size() != 0:\n",
    "            if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "                break\n",
    "                \n",
    "        for neighbor in graph.neighbors(current[1]): #Loop through neighbors of current that are not in visited\n",
    "            total_edge_cost = graph.get_edge_weight(current[1], neighbor) + parents_continue[current[1]][1]\n",
    "            if neighbor not in parents_continue: #If neighbor has no parent yet\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Assign parent\n",
    "                temp_list.append((total_edge_cost, neighbor)) #Append to list    \n",
    "            elif total_edge_cost < parents_continue[neighbor][1]: #If parent exists, but we found a cheaper path\n",
    "                parents_continue[neighbor] = [current[1], total_edge_cost] #Update parent\n",
    "                q_continue.update(neighbor, total_edge_cost) #Update queue                 \n",
    "        sort_and_append(q_continue, temp_list) #Sort list alphabetically and append to queue    \n",
    "        \n",
    "    if q_continue.top()[0] >= max(c_x_path_cost_1, ab_path_cost):\n",
    "        no_need_to_compare = True\n",
    "    \n",
    "    #######################################\n",
    "    \n",
    "    ### OPTIMIZE THIRD PATH C - (if applicable)\n",
    "    if not no_need_to_compare:\n",
    "        crossover_points = list(eval('v' + str(c_search_x_second)).intersection(set((q_continue.get_nodes()))))\n",
    "        path_costs = []\n",
    "        intersect_node_c_x_second = q_continue.top()[2]\n",
    "        for point in crossover_points:\n",
    "            path_costs.append([point, parents_continue[point][1] + eval('parents_' + str(c_search_x_second))[point][1]])    \n",
    "        path_costs = sorted(path_costs, key=lambda x: x[1])\n",
    "        path_costs = [sublist for sublist in path_costs if intersect_node_c_x_second != sublist[0]]\n",
    "        if not no_need_to_compare:\n",
    "            intersection_cost = parents_continue[intersect_node_c_x_second][1] + eval('parents_' + str(c_search_x_second))[intersect_node_c_x_second][1]\n",
    "            if len(path_costs) != 0:\n",
    "                if intersection_cost > path_costs[0][1]:\n",
    "                    intersect_node_c_x_second = path_costs[0][0] #Update intersect node \n",
    "            c_x_path_cost_2 = parents_continue[intersect_node_c_x_second][1] + eval('parents_' + str(c_search_x_second))[intersect_node_c_x_second][1]\n",
    "    \n",
    "    ######################################\n",
    "    \n",
    "    ### Build Path\n",
    "    #Case 1: CB was determined to be longer than max of (AB, AC) and therefore never searched for\n",
    "    if no_need_to_compare:\n",
    "        c_path = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp_path = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp_path.reverse()\n",
    "        c_path = c_path + temp_path\n",
    "        if c_search_x_initial == met[1]:\n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        else: \n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "            \n",
    "        full_path = c_path + ab_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "    \n",
    "    #Case 2: CB was found. If CA <= CB\n",
    "    if c_x_path_cost_1 <= c_x_path_cost_2:\n",
    "        c_path = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp_path = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp_path.reverse()\n",
    "        c_path_1 = c_path + temp_path\n",
    "        if (c_x_path_cost_2 < ab_path_cost) and (c_x_path_cost_1 != c_x_path_cost_2):\n",
    "            temp1 = backtrack_and_append(intersect_node_c_x_second, eval('parents_' + str(c_search_x_second)))\n",
    "            temp2 = backtrack_and_append(intersect_node_c_x_second, parents_continue)\n",
    "            temp2.reverse()\n",
    "            c_path_2 = temp1 + temp2\n",
    "            full_path = c_path_2 + c_path_1\n",
    "            result_path = filter_nodes(full_path)\n",
    "            return result_path\n",
    "        else:\n",
    "            if c_search_x_initial == met[1]:\n",
    "                ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "                b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "                b_path.reverse()\n",
    "                ab_path = ab_path + b_path\n",
    "            else: \n",
    "                ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "                b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "                b_path.reverse()\n",
    "                ab_path = ab_path + b_path\n",
    "            full_path = c_path_1 + ab_path\n",
    "            result_path = filter_nodes(full_path)\n",
    "            return result_path\n",
    "    \n",
    "    #Case 3: CB was found. If CA > CB\n",
    "    c_path = backtrack_and_append(intersect_node_c_x_second, parents_continue)\n",
    "    temp_path = backtrack_and_append(intersect_node_c_x_second, eval('parents_' + str(c_search_x_second)))\n",
    "    temp_path.reverse()\n",
    "    c_path = c_path + temp_path\n",
    "    if (c_x_path_cost_1 < ab_path_cost) and (c_x_path_cost_1 != c_x_path_cost_2):\n",
    "        temp1 = backtrack_and_append(intersect_node_c_x_initial, eval('parents_' + str(c_search_x_initial)))\n",
    "        temp2 = backtrack_and_append(intersect_node_c_x_initial, parents_continue)\n",
    "        temp2.reverse()\n",
    "        c_path_2 = temp1 + temp2\n",
    "        full_path = c_path_2 + c_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "    else:\n",
    "        if c_search_x_second == met[1]:\n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        else: \n",
    "            ab_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[2])))\n",
    "            b_path = backtrack_and_append(ab_intersect, eval('parents_' + str(met[1])))\n",
    "            b_path.reverse()\n",
    "            ab_path = ab_path + b_path\n",
    "        \n",
    "        full_path = c_path + ab_path\n",
    "        result_path = filter_nodes(full_path)\n",
    "        return result_path\n",
    "        \n",
    "##########################################  \n",
    "##########################################  \n",
    "##########################################  \n",
    "\n",
    "def filter_nodes(full_path):\n",
    "    result = []\n",
    "    for i in range(len(full_path) - 1):\n",
    "        if full_path[i] != full_path[i + 1]:\n",
    "            result.append(full_path[i])\n",
    "    result.append(full_path[-1])\n",
    "    return result\n",
    "def sort_and_append(q_2_append_2, list_2_append):\n",
    "    sorted_tuples = sorted(list_2_append, key=lambda x: x[1]) #Sort alphabetically\n",
    "    for element in sorted_tuples: #Append to priority queue\n",
    "        q_2_append_2.append(element)\n",
    "\n",
    "def backtrack_and_append(intersection_node, parent_directory):\n",
    "    path, counter = [], 0\n",
    "    back_track = intersection_node\n",
    "    while back_track != \"stop\":\n",
    "        path.insert(0, back_track)\n",
    "        back_track = parent_directory[back_track][0]\n",
    "    return path\n",
    "    \n",
    "def who_met_2(q1, v2,num2, v3,num3):\n",
    "    if q1 in v2:\n",
    "        return str(num2)\n",
    "    elif q1 in v3:\n",
    "        return str(num3)\n",
    "    return None\n",
    "\n",
    "def who_met_3(q1, q2, q3, v1, v2, v3, p1, p2, p3):\n",
    "    intersections = []\n",
    "    if q1.top()[2] in v2:\n",
    "        intersections.append((q1.top()[2], '1', '2', p1[q1.top()[2]][1] + p2[q1.top()[2]][1]))\n",
    "    if q1.top()[2] in v3:\n",
    "        intersections.append((q1.top()[2], '1', '3', p1[q1.top()[2]][1] + p3[q1.top()[2]][1]))\n",
    "    if q2.top()[2] in v1:\n",
    "        intersections.append((q2.top()[2], '2', '1', p2[q2.top()[2]][1] + p1[q2.top()[2]][1]))\n",
    "    if q2.top()[2] in v3:\n",
    "        intersections.append((q2.top()[2], '2', '3', p2[q2.top()[2]][1] + p3[q2.top()[2]][1]))\n",
    "    if q3.top()[2] in v1:\n",
    "        intersections.append((q3.top()[2], '3', '1', p3[q3.top()[2]][1] + p1[q3.top()[2]][1]))\n",
    "    if q3.top()[2] in v2:\n",
    "        intersections.append((q3.top()[2], '3', '2', p3[q3.top()[2]][1] + p2[q3.top()[2]][1]))\n",
    "    if intersections:\n",
    "        return min(intersections, key=lambda x: x[3])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3086d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "The implementation of various search algorithms, particularly focusing on bi-directional and tri-directional searches, marks a significant exploration into the complexities of artificial intelligence problem-solving techniques. While fundamental algorithms like Breadth-First Search, A*, and Dijkstra's provide a strong foundation, extending these concepts into bi-directional and tri-directional contexts introduces a layer of complexity that challenges both the understanding and the skills of any algorithm designer.\n",
    "\n",
    "#### Key Achievements and Challenges\n",
    "\n",
    "The primary challenge in extending traditional search algorithms to bi-directional and tri-directional search is not merely about getting them to work but optimizing them to minimize the count of explored nodes and improve on time and space complexities. This project highlights the intricacies involved in designing such algorithms to efficiently converge upon solutions by meeting at a mutual node from multiple directions, thereby significantly reducing the search space and potentially the computational load.\n",
    "\n",
    "#### Optimization and Efficiency\n",
    "\n",
    "The development and refinement of bi-directional and tri-directional search algorithms have underscored the importance of efficient algorithm design in AI. These methods can vastly outperform single-direction search algorithms in complex and large-scale problem spaces by strategically exploring from multiple points simultaneously, thus approaching the solution more rapidly.\n",
    "\n",
    "#### Reflections and Future Directions\n",
    "\n",
    "This exercise has not only reinforced the value of foundational search algorithms but also demonstrated the advanced capabilities required to implement more sophisticated techniques effectively. For future work, there remains ample scope to refine these algorithms further, enhancing their efficiency and adaptability to a broader range of problems. Investigating the integration of more dynamic heuristic functions and exploring machine learning approaches to predict optimal convergence points in tri-directional searches could provide valuable directions for research.\n",
    "\n",
    "In conclusion, this project has been an enlightening journey into the depths of algorithmic problem-solving within AI. The successful implementation of bi-directional and tri-directional searches, in particular, offers a robust framework for tackling complex search problems, paving the way for more innovative solutions in the field of artificial intelligence."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
